{
  "instruction": "Develop a chatbot in Python using Natural Language Processing and Machine Learning.",
  "buggy_code": "import nltk\nfrom nltk.stem.lancaster import LancasterStemmer\nstemmer = LancasterStemmer()\nimport json\nwith open('data.json') as json_data:\n    data = json.load(json_data)\nwords = []\nlabels = []\ndocs_x = []\ndocs_y = []\nfor intent in data['intents']:\n    for pattern in intent['patterns']:\n        wrds = nltk.word_tokenize(pattern)\n        words.extend(wrds)\n        docs_x.append(wrds)\n        docs_y.append(intent['tag'])\n        if intent['tag'] not in labels:\n            labels.append(intent['tag'])\nwords = [stemmer.stem(w.lower()) for w in words if w != '?']\nwords = sorted(list(set(words)))\ntraining = []\noutput = []\nout_empty = [0 for _ in range(len(labels))]\nfor x, doc in enumerate(docs_x):\n    bag = []\n    wrds = [stemmer.stem(w) for w in doc]\n    for w in words:\n        if w in wrds:\n            bag.append(1)\n        else:\n            bag.append(0)\n    output_row = out_empty[:]\n    output_row[labels.index(docs_y[x])] = 1\n    training.append(bag)\n    output.append(output_row)\nimport numpy as np\ntraining = np.array(training)\noutput = np.array(output)\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nmodel = Sequential()\nmodel.add(Dense(128, input_shape=(len(training[0]),), activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(len(output[1]), activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(training, output, epochs=1000, batch_size=8, verbose=1)\nimport pickle\npickle.dump(model, open('model.pkl', 'wb'))",
  "line_no": 59,
  "line_no_percent": "123%"
}