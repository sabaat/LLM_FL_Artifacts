{
  "instruction": "This code performs performance tests based on tests/highlevel/high-in-low6-memory.py. The data overhead is at ~6.5 ms / MB. The database upload overhead is about the same (7 ms / MB) with a flatfile backend. Database download is almost free. A structured cell auth operation is about 10 ms. Map-list macro evaluation is cheap, 5 ms per (parallel) transformation. Re-translation is about 20 ms per transformation (on top of the macro). Expression evaluation is about 10 ms + 0.5 ms / MB (of input + output) per transformation (speculative relationship!). Non-linear scaling is observed between 100 and 1000 parallel transformations, a x4 slowdown is observed for the last three overheads above. Mixed-to-str conversion is expensive, don't do it!",
  "buggy_code": "\"\"\"\nPerformance tests based on tests/highlevel/high-in-low6-memory.py\nSee also auth-*py.\n\n- Data overhead is now at ~6.5 ms / MB.\n  A lot of the data overhead comes from json.dumps. This is to build mixed cells.\n  The rest is from get_hash.\n  Pure Python version (with get_hash and dumps) is at 6.3 ms / MB,\n  so the rest of the data overhead is fine!\n\n- Database upload overhead is about the same (7 ms / MB) with a flatfile backend\n  Database download is almost free.\n\n- A structured cell auth operation is about 10 ms.\n\n- map-list macro evaluation is cheap, 5 ms per (parallel) transformation\n\n- re-translation is about 20 ms per transformation (on top of the macro)\n\n- expression evaluation is about 10 ms + 0.5 ms / MB (of input + output) per transformation\n  (speculative relationship!)\n\n- BUT: Non-linear scaling:\n  between 100 and 1000 parallel transformations, a x4 slowdown is observed for the last three overheads above.\n\n\nNOTE: Mixed-to-str conversion is expensive, don't do it!\n\n\n\n\"\"\"\n\nimport sys\nimport seamless\n\nimport seamless.core.execute\nseamless.core.execute.DIRECT_PRINT = True\n\nseamless.database_sink.connect()\nseamless.database_cache.connect()\n\nseamless.set_ncores(8) ###\nseamless.set_parallel_evaluations(100)  ###\n\nseamless.set_parallel_evaluations(20)  ###\n\n\"\"\"\nimport logging\nlogging.basicConfig()\nlogging.getLogger(\"seamless\").setLevel(logging.DEBUG)\n\"\"\"\n\nfrom seamless.highlevel import Context, Cell, Macro\nfrom seamless.highlevel.library import LibraryContainer\n\nimport time\nimport cProfile\ncProfile.profiler = cProfile.Profile()\n\nmylib = LibraryContainer(\"mylib\")\nmylib.map_list_N = Context()\ndef constructor(ctx, libctx, context_graph, inp, result):\n    m = ctx.m = Macro()\n    m.graph = context_graph\n    m.pins.result = {\"io\": \"output\", \"celltype\": \"mixed\", \"hash_pattern\": {\"!\": \"#\"}}\n\n    ctx.inp = Context()\n    ctx.cs_inp = Context()\n    inp_prefix = \"INPUT_\"\n    m.inp_prefix = inp_prefix\n    for key in inp:\n        c = Cell()\n        ctx.inp[key] = c\n        c.hash_pattern = {\"!\": \"#\"}\n        inp[key].connect(c)\n        ctx.cs_inp[key] = Cell(\"checksum\")\n        ctx.cs_inp[key] = ctx.inp[key]\n        setattr(m, inp_prefix + key , ctx.cs_inp[key])\n\n    def map_list_N(ctx, inp_prefix, graph, **inp):\n        first_k = list(inp.keys())[0]\n        length = len(inp[first_k])\n        first_k = first_k[len(inp_prefix):]\n        for k0 in inp:\n            k = k0[len(inp_prefix):]\n            if len(inp[k0]) != length:\n                err = \"all cells in inp must have the same length, but '{}' has length {} while '{}' has length {}\"\n                raise ValueError(err.format(k, len(inp[k0]), first_k, length))\n\n        print(\"LENGTH\", length)\n\n        from seamless.core import Cell as CoreCell\n        from seamless.core.unbound_context import UnboundContext\n        pseudo_connections = []\n        ctx.result = cell(\"mixed\", hash_pattern = {\"!\": \"#\"})\n\n        ctx.sc_data = cell(\"mixed\", hash_pattern = {\"!\": \"#\"})\n        ctx.sc_buffer = cell(\"mixed\", hash_pattern = {\"!\": \"#\"})\n        ctx.sc = StructuredCell(\n            data=ctx.sc_data,\n            buffer=ctx.sc_buffer,\n            inchannels=[(n,) for n in range(length)],\n            outchannels=[()],\n            hash_pattern = {\"!\": \"#\"}\n        )\n\n        for n in range(length):\n            hc = HighLevelContext(graph)\n\n            subctx = \"subctx%d\" % (n+1)\n            setattr(ctx, subctx, hc)\n\n            if not hasattr(hc, \"inp\"):\n                raise TypeError(\"map_list_N context must have a subcontext called 'inp'\")\n            hci = hc.inp\n            if not isinstance(hci, UnboundContext):\n                raise TypeError(\"map_list_N context must have an attribute 'inp' that is a context, not a {}\".format(type(hci)))\n\n            for k0 in inp:\n                k = k0[len(inp_prefix):]\n                if not hasattr(hci, k):\n                    raise TypeError(\"map_list_N context must have a cell called inp.'{}'\".format(k))\n                if isinstance(hci[k], StructuredCell):\n                    raise TypeError(\"map_list_N context has a cell called inp.'{}', but its celltype must be mixed, not structured\".format(k))\n                if not isinstance(hci[k], CoreCell):\n                    raise TypeError(\"map_list_N context must have an attribute inp.'{}' that is a cell, not a {}\".format(k, type(hci[k])))\n                if hci[k].celltype != \"mixed\":\n                    raise TypeError(\"map_list_N context has a cell called inp.'{}', but its celltype must be mixed, not {}\".format(k, hci[k].celltype))\n\n                con = [\"..\" + k], [\"ctx\", subctx, \"inp\", k]\n                pseudo_connections.append(con)\n                cs = inp[k0][n]\n                hci[k].set_checksum(cs)\n\n            resultname = \"result%d\" % (n+1)\n            setattr(ctx, resultname, cell(\"mixed\"))\n            c = getattr(ctx, resultname)\n            hc.result.connect(c)\n            c.connect(ctx.sc.inchannels[(n,)])\n            con = [\"ctx\", subctx, \"result\"], [\"..result\"]\n            pseudo_connections.append(con)\n\n        ctx.sc.outchannels[()].connect(ctx.result)\n        ctx._pseudo_connections = pseudo_connections\n        print(\"/MACRO\")\n\n        \"\"\"\n        import logging\n        logging.basicConfig()\n        logging.getLogger(\"seamless\").setLevel(logging.DEBUG)\n        \"\"\"\n\n        import cProfile\n        cProfile.profiler.enable()\n\n    m.code = map_list_N\n    ctx.result = Cell()\n    ctx.result.hash_pattern = {\"!\": \"#\"}\n    ctx.result = m.result\n    result.connect_from(ctx.result)\n\n\nmylib.map_list_N.constructor = constructor\nmylib.map_list_N.params = {\n    \"context_graph\": \"context\",\n    \"inp\": {\n        \"type\": \"celldict\",\n        \"io\": \"input\"\n    },\n    \"result\": {\n        \"type\": \"cell\",\n        \"io\": \"output\"\n    },\n}\n\nctx = Context()\nctx.adder = Context()\nsctx = ctx.adder\nsctx.inp = Context()\nsctx.inp.a = Cell(\"mixed\")\nsctx.inp.b = Cell(\"mixed\")\nsctx.a = Cell(\"mixed\")\nsctx.b = Cell(\"mixed\")\nsctx.a = sctx.inp.a\nsctx.b = sctx.inp.b\ndef add(a,b):\n    return\n    print(\"ADD\", a[:10])\n    return a+b\nsctx.add = add\nsctx.add.a = sctx.a\nsctx.add.b = sctx.b\nsctx.result = sctx.add\nsctx.result.celltype = \"mixed\"\nctx.compute()\n\nctx.data_a = Cell()\nctx.data_a.hash_pattern = {\"!\": \"#\"}\nctx.data_b = Cell()\nctx.data_b.hash_pattern = {\"!\": \"#\"}\nctx.compute()\n\n\nrepeat = int(10e6)\nfor n in range(1000):\n    a = \"A:%d:\" % n + str(n%10) * repeat\n    b = \"B:%d:\" % n + str(n%10) * repeat\n    ctx.data_a[n] = a\n    ctx.data_b[n] = b\n    if n % 20 == 0:\n        ctx.compute()\n    print(n+1)\n\nctx.compute()\nprint(ctx.data_a.checksum)\nprint(ctx.data_b.checksum)\n\n\"\"\"\nctx.data_a.set_checksum(\"d07050610c50de8c810aa1d1e322786ed8932cf6eafa0fbe1f132b2c881af9c2\")\nctx.data_b.set_checksum(\"374c02504f89ed0a760b03c3e1fd2258988576b919d763254709b66fc7bfb22e\")\nctx.compute()\n\n\"\"\"\n\n\n\n\nctx.compute()\n\n\"\"\"\nIf there is no database (100 x repeat 10e6):\n- 13 secs up to here (6.5 ms per MB)\n- 0.5 secs to evaluate the macro\n- 2.3 secs (2.8 - 0.5) for re-translation (23 ms per transformer)\n- 32 secs total time, which leaves 32 - 13 - 0.5 = 18.5 secs for transformation and expression evaluation\n  Since 13 secs is required for calculate checksum and decoding, that means ~5.5 secs (55 ms per transformer) overhead\n  This is a supplement of 32 ms over just re-translation\n\nIf there is no database (100 x repeat 5):\n- 2.3 secs up to here (12 ms per auth operation)\n- Still 0.5 secs to evaluate the macro\n- Still 2.3 secs (2.8 - 0.5) for re-translation (23 ms per transformer, independent of data size!)\n- 6.2 secs total time, which leaves 6.2 - 2.3 - 0.5 = 3.5 secs for transformation and expression evaluation\n  This is an overhead of 35 ms per transformer, a supplement of just 12 ms over re-translation\n  The 20 ms reduction compared to above comes from not handling 2x10 MB of input and 20 MB of output,\n  so that's 0.5 ms/MB.\n\nIf there is no database (1000 x repeat 5):\n- 11.7 secs up to here (12 ms per auth operation). So scales linearly.\n- 6.5 secs to evaluate the macro, so scales about linearly\n- 98 secs (104.5 - 6.5) for re-translation, which is 4x slower than above  (98 ms)\n- 145 secs total time, which leaves 145 - 11.7 - 6.5 = 127 secs for transformation and expression evaluation\n  This is an overhead of 127 ms per transformer, which is 4x slower than above (127 ms).\n  => So in principle, 90 sconds slower than might be\n    - Some 45 secs is await-upon-connection-tasks, this could be optimized?\n    - 12 seconds from isinstance is probably unavoidable\n    - 9 seconds comes from validate deep structure, that may be unavoidable\n    - 5 seconds each from taskmanager.add_task (61k tasks) and asyncio.Task.done (119 million tasks). Avoidable?\n  => do maplist-inside-maplist\n\nIf the database has not been filled:\n- 27.5 secs up to here\nIf the database has been filled:\n- 14 secs up to here: to synthesize the data, and to verify that all is present\n  So the raw upload is 13.5 seconds (27.5 - 14); and communication with the DB delays only 1 sec.\n- 1.5 secs up to here, with the above elision.\n\nWith the database:\n- 1.5 secs to evaluate the macro (DB slows down!)\n- 5.5 secs for re-translation\n- 45.7 secs total time, which leaves 45.7 - 5.5 - 1.5 = 38.5 secs for transformation and expression evaluation\n  Compare this to the 18.5 secs w/o database, this is a loss of 20 secs.\n  But we have to count the download of the inputs and upload of the results.\n  When removing the tfr entries from the database, transformations will be repeated, but no buffers will be uploaded,\n  as the sink knows them already.\n  This brings total time down to 32 secs, the same as no database!\n  So all of the extra overhead is from upload, and download is almost free. (This could be hard disk caching, though)\n- 5.5 secs total time with pulling transformation results out of the DB. Again, download is almost free.\n\n\nBig test with the database (1000 x repeat 10e6):\n- Total time 940 secs. Data upload overhead should be ~120 secs, and Seamless data overhead should be ~140 secs.\n- 142 secs for re-translation + macro evaluation (142 ms / transformation), a factor 6 slowdown\n- 940 - 142 - 120 - 140 = ~540 secs for evaluation\n   I.e. 540 ms per transformation. If the same slowdown applies, it would have been 90.\n   But we would have expected 30. So a larger slowdown (fewer parallel expressions may have been a cause too)\n\"\"\"\n\nctx.result = Cell()\nctx.result.hash_pattern = {\"!\": \"#\"}\nctx.compute()\n\nctx.include(mylib.map_list_N)\nctx.inst = ctx.lib.map_list_N(\n    context_graph = ctx.adder,\n    inp = {\"a\": ctx.data_a, \"b\": ctx.data_b},\n    result = ctx.result\n)\nctx.compute()\n\nprint(\"Exception:\", ctx.inst.ctx.m.exception)\nprint(ctx.result.data)\n\nimport pstats\nsortby = 'tottime'\nps = pstats.Stats(cProfile.profiler).sort_stats(sortby)\nps.print_stats(40)\n\nt0 = time.time()\n\"\"\"\nprint(\"Re-set\")\ngraph = ctx.get_graph()\nctx_dummy = Context()\ndummy_graph = ctx_dummy.get_graph()\nctx.set_graph(dummy_graph)\nctx.translate(force=True)\nctx.compute()\nprint(time.time()-t0)\nprint(\"Re-eval\")\nctx.set_graph(graph)\n\"\"\"\n\"\"\"\nctx.translate(force=True)\nctx.compute()\nprint(time.time()-t0)\n\"\"\"\n",
  "line_no": 187,
  "line_no_percent": "57%"
}