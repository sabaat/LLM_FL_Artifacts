{
  "instruction": "Create an environment object that can execute and analyze Python code. The environment includes a set of predefined global variables and functions, as well as the ability to add additional global variables. The environment can execute Python code and analyze it for variable usage and imports. The environment also includes a stdout object that can be used to capture and display output from executed code.",
  "buggy_code": "import os\nimport ast\nimport traceback\nimport time\nimport sys\nimport types\nimport builtins\nimport collections\nimport astor\nimport weakref\nfrom .jsonify import jsonify, jsonify_print, jsonify_print_expr\nfrom .datalayer import Analysis, Execution, FileEdit\nfrom .router import send\nfrom . import stdlib\n\ndef now():\n    return int(time.time() * 1000)\n\nclass Environment:\n\n    extra_globals = {}\n\n    active = weakref.WeakSet()\n\n    def __init__(self, path):\n        self.path = path\n        self.globals = {\n            \"print\": jsonify_print,\n            \"print_expr\": jsonify_print_expr,\n            \"jsonify\": jsonify,\n            \"jsonify_print\": jsonify_print,\n            \"listdir\": stdlib.listdir,\n            \"__builtins__\": __builtins__,\n            \"FILES\": stdlib.FilesDict(self.path),\n        }\n        for name in stdlib.builtin_names:\n            self.globals[name] = getattr(stdlib, name)\n        self._cached_analysis = {}\n        self.active.add(self)\n\n    predefined_names = set([\"parsed\"])\n\n    def init_commands(self):\n        \"\"\"Returns a list of commands that represent the existing state of the\n        filesystem\"\"\"\n        for path in os.listdir(self.path):\n            if path.endswith(\".json\"):\n                continue\n            if not os.path.isfile(os.path.join(self.path, path)):\n                continue\n            try:\n                with open(os.path.join(self.path, path), \"r\") as fp:\n                    content = fp.read()\n                yield FileEdit(filename=path, content=content, external_edit=True)\n            except UnicodeDecodeError:\n                pass\n\n    def fixup_globals(self):\n        for name, value in self.extra_globals.items():\n            self.globals.setdefault(name, value)\n\n    def execute(self, filename, content, subexpressions=False):\n        print(\"Executing\", filename, subexpressions)\n        self.fixup_globals()\n        stdout = Stdout()\n        compiled = None\n        try:\n            parsed = ast.parse(content, filename, mode='exec')\n            RewriteExprToPrint(subexpressions).walk(parsed)\n            var_inspect = VariableInspector()\n            var_inspect.walk(parsed)\n            print(\"varsed used:\", sorted(var_inspect.used), \"set:\", sorted(var_inspect.set), \"imported:\", var_inspect.imports)\n            compiled = compile(parsed, filename, 'exec')\n        except:\n            stdout.write(traceback.format_exc())\n\n        def displayhook(value):\n            stdout.write_repr(value)\n\n        orig_displayhook = sys.displayhook\n        sys.displayhook = displayhook\n        orig_stdout = sys.stdout\n        orig_stderr = sys.stderr\n        sys.stdout = stdout\n        sys.stderr = stdout\n        self.globals[\"parsed\"] = parsed\n        self.globals[\"ast\"] = ast\n        globals_before = self.globals.copy()\n        start = time.time()\n        try:\n            try:\n                if compiled:\n                    exec(compiled, self.globals)\n            except:\n                traceback.print_exc()\n        finally:\n            end = time.time()\n            sys.dipslayhook = orig_displayhook\n            sys.stdout = orig_stdout\n            sys.stderr = orig_stderr\n        local_scope = dict(\n            (name, value)\n            for name, value in self.globals.items()\n            if name not in globals_before or globals_before[name] is not value)\n        defines = dict(\n            (key, {\n                \"json\": jsonify(local_scope[key]),\n                \"type\": str(type(local_scope[key])),\n            })\n            for key in local_scope\n            if not isinstance(local_scope[key], types.ModuleType))\n        command = Execution(\n            filename=filename,\n            content=content,\n            emitted=stdout.emitted,\n            defines=defines,\n            start_time=int(start * 1000),\n            end_time=int(end * 1000),\n            exec_time=int((end - start) * 1000),\n            with_subexpressions=subexpressions,\n        )\n        send(command)\n\n    def analyze(self, filename, content):\n        print(\"Analyzing\", filename)\n        properties = {}\n        try:\n            parsed = ast.parse(content, filename, mode='exec')\n            var_inspect = VariableInspector()\n            var_inspect.walk(parsed)\n        except:\n            return\n            properties[\"parse_error\"] = jsonify(traceback.format_exc())\n        else:\n            properties = var_inspect.json\n        if properties != self._cached_analysis.get(filename):\n            self._cached_analysis[filename] = properties\n            send(Analysis(filename=filename, content=content, properties=properties))\n\n\nclass VariableInspector(astor.TreeWalk):\n\n    builtin_names = dir(builtins)\n\n    def init_variables(self):\n        self.used = set()\n        self.set = set()\n        self.imports = set()\n        self.in_target = False\n\n    @property\n    def json(self):\n        used = set(self.used)\n        for key in self.builtin_names:\n            used.discard(key)\n        for key in self.set:\n            used.discard(key)\n        for key in Environment.predefined_names:\n            used.discard(key)\n        return {\n            \"variables_used\": list(used),\n            \"variables_set\": list(self.set),\n            \"imports\": list(self.imports)\n        }\n\n    def pre_arg(self):\n        self.set.add(self.cur_node.arg)\n\n    def pre_Name(self):\n        if self.in_target:\n            self.set.add(self.cur_node.id)\n        else:\n            self.used.add(self.cur_node.id)\n\n    def pre_For(self):\n        return\n        self.process_assignment(self.cur_node.target)\n\n    def pre_Assign(self):\n        self.process_assignment(self.cur_node.targets)\n\n    def pre_withitem(self):\n        self.process_assignment(self.cur_node.optional_vars)\n\n    def pre_ExceptHandler(self):\n        if self.cur_node.name:\n            self.set.add(self.cur_node.name)\n\n    def pre_alias(self):\n        name = self.cur_node.asname or self.cur_node.name\n        name = name.split(\".\")[0]\n        self.set.add(name)\n        self.imports.add(name)\n\n    def pre_FunctionDef(self):\n        self.set.add(self.cur_node.name)\n\n    def pre_ListComp(self):\n        self.process_assignment(self.cur_node.elt)\n\n    def process_assignment(self, item):\n        if isinstance(item, list):\n            for x in item:\n                self.process_assignment(x)\n            return\n        old_in_target = self.in_target\n        self.in_target = True\n        try:\n            self.walk(item)\n        finally:\n            self.in_target = old_in_target\n\nclass RewriteExprToPrint(astor.TreeWalk):\n\n    expr_node_types = \"\"\"\n    UnaryOp\n    BinOp\n    BoolOp\n    Compare\n    Call\n    IfExp\n    Attribute\n    Subscript\n    ListComp SetComp GeneratorExp DictComp\n    \"\"\".split()\n\n    def __init__(self, subexpressions=False):\n        self.subexpressions = subexpressions\n        self.id_counter = 0\n        astor.TreeWalk.__init__(self)\n        if self.subexpressions:\n            for method in self.expr_node_types:\n                self.pre_handlers[method] = self.save_node_name\n                self.post_handlers[method] = self.fixup_subexpressions\n            del self.post_handlers['Module']\n\n    def post_Name(self):\n        if not self.subexpressions:\n            return\n        if isinstance(self.cur_node.ctx, ast.Load):\n            self.replace(self.rewrite_expr(self.cur_node))\n\n    def post_Module(self):\n        node = self.cur_node\n        node.body = [\n            self.rewrite_expr(n) if isinstance(n, ast.Expr) else n\n            for n in node.body]\n\n    def save_node_name(self):\n        self.cur_node.astor_repr = astor.to_source(self.cur_node)\n\n    def fixup_subexpressions(self):\n        new_node = self.rewrite_expr(self.cur_node, self.cur_node.astor_repr)\n        self.replace(new_node)\n\n    def rewrite_expr(self, node, expr_string=None):\n        if expr_string is None:\n            expr_string = astor.to_source(node)\n        node_string = ast.Str(s=expr_string)\n        self.id_counter += 1\n        if isinstance(node, ast.Expr):\n            new_node = ast.Expr(\n                ast.Call(\n                    func=ast.Name(id='print_expr', ctx=ast.Load()),\n                    args=[node_string, node.value, ast.Num(n=self.id_counter)],\n                    keywords=[],\n                    starargs=None,\n                )\n            )\n            new_node.is_print_expr = True\n        else:\n            new_node = ast.Call(\n                func=ast.Name(id='print_expr', ctx=ast.Load()),\n                args=[node_string, node, ast.Num(n=self.id_counter)],\n                keywords=[],\n                starargs=None,\n            )\n            new_node.is_print_expr = True\n        ast.fix_missing_locations(new_node)\n        return new_node\n\n\nclass Stdout:\n\n    total_exprs_limit = 100\n    expr_limit = 10\n\n    def __init__(self):\n        self.emitted = []\n        self.total_exprs_printed = 0\n        self.exprs_printed = collections.Counter()\n\n    def write(self, content):\n        self.emitted.append({\n            \"type\": \"print\",\n            \"time\": now(),\n            \"parts\": [{\"type\": \"str\", \"str\": content}],\n        })\n\n    def writejson(self, json):\n        assert json.get(\"type\"), \"JSON objects must have a type\"\n        json.setdefault(\"time\", now())\n        self.emitted.append(json)\n\n    def write_repr(self, o):\n        self.emitted.append(jsonify(o))\n\n    def flush(self):\n        pass\n\ndef add_global(name, value):\n    Environment.extra_globals[name] = value\n    Environment.predefined_names.add(name)\n    for env in Environment.active:\n        env.globals.setdefault(name, value)\n",
  "line_no": 176,
  "line_no_percent": "56%"
}