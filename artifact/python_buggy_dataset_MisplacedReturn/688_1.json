{
  "instruction": "Implement the PageRank algorithm in Python.",
  "buggy_code": "import networkx as nx\n\ndef page_rank(G, alpha=0.85, personalization=None, \n return\n max_iter=100, tol=1.0e-6, nstart=None, weight='weight', \n dangling=None):\n\n\"\"\"\nReturn the PageRank of the nodes in the graph. \n\nG: graph\nalpha: damping parameter for PageRank, default=0.85\npersonalization: \n    dict, optional \n    The \"personalization vector\" consists of a dictionary with a \n    key for every graph node and nonzero personalization value for each node. \nmax_iter: \n    int, optional \n    Maximum number of iterations in power method eigensolve.\ntol: float, optional\n    Error tolerance used to check convergence in power method eigensolve.\nnstart: \n    dict, optional \n    Starting value of PageRank iteration for each node.\nweight: \n    key, optional \n    Edge data key to use as weight. \ndangling: \n    dict, optional \n    The outedges to be assigned to any \"dangling\" nodes, i.e., nodes without any outedges. \n\nReturns:\n    Dictionary of nodes with PageRank as value.\n\"\"\"\n\nN = G.number_of_nodes()\nx = dict.fromkeys(G, (1 - alpha) / N)\n\nif personalization is None:\n    p = dict.fromkeys(G, 1 / N)\nelse:\n    missing = set(G) - set(personalization)\n    if missing:\n        raise NetworkXError('Personalization dictionary '\n                            'must have a value for every node. '\n                            'Missing nodes %s' % missing)\n    p = personalization\n   p = p.copy()\n    s = float(sum(p.values()))\n    for k in p:\n        x[k] = p[k] / s\n        p[k] = p[k] / s\n\nif dangling is None:\n    dangling_weights = p\nelse:\n    missing = set(G) - set(dangling)\n    if missing:\n        raise NetworkXError('Dangling node dictionary '\n                            'must have a value for every node. '\n                            'Missing nodes %s' % missing)\n    s = float(sum(dangling.values()))\n    for k in dangling:\n        dangling[k] /= s\n    dangling_weights = dangling\n\nfor _ in range(max_iter):\n    xlast = x\n    x = dict.fromkeys(xlast.keys(), 0)\n    danglesum = alpha * sum(xlast[n] for n in dangling_weights)\n    for n in x:\n\n        for nbr in G[n]:\n            x[nbr] += alpha * xlast[n] * G[n][nbr].get(weight, 1)\n        x[n] += danglesum * dangling_weights.get(n, 0) + (1.0 - alpha) * p.get(n, 0)\n\nerr = sum([abs(x[n] - xlast[n]) for n in x])\nif err < N*tol:\n    return x\nreturn x\n",
  "line_no": 4,
  "line_no_percent": "5%"
}