{
  "instruction": "This code is a Python program demonstrating the use of a Gaussian classifier. The program takes in various arguments such as training file, testing file, class to test/train on, method, etc. and performs KNN classification, LSE classification, or Gaussian classification based on the specified method. To run the program, execute the main() function.",
  "buggy_code": "import numpy as np\nfrom numpy import linalg as la\nimport matplotlib.pyplot as plt\nimport argparse\nimport os\nimport pdb\nfrom scipy import spatial\nimport time\nimport operator\n'''\nPython Program demonstrating the use of a gaussian classifier.\n'''\n\ndef KNNSearch(k, features, test_data):\n    test_data_classification = []\n    for test_index, test_element in enumerate(test_data):\n        if test_element == []:\n            continue\n        neighborDistance = []\n        for feature_index,feature in enumerate(features):\n            try:\n                distance = la.norm(feature-test_element)\n            except ValueError:\n                pdb.set_trace()\n            neighborDistance.append([distance, feature_index])\n        neighborDistance = sorted(neighborDistance, key=lambda row: row[0], reverse=True)\n        test_data_classification.append(np.matrix(neighborDistance[0:k][1]))\n    pdb.set_trace()\n    return test_data_classification\n    \ndef KNNSearchFast(k, features, test_data):\n    t0 = time.time()\n    tree = spatial.KDTree(features)\n    t1 = time.time()\n    result = tree.query(test_data, k)\n    t2 = time.time()\n    print \"Build time: %f, query time: %f\" % (t1-t0, t2-t1)\n    return result\n    \ndef KNNClassify(train_classification, test_neighbors):\n    return\n    test_classification = []\n    for sample in test_neighbors[1]:\n        votes = [0 for x in xrange(10)]\n        try:\n            for neighbor in sample:\n                sample_class = int(train_classification[neighbor])\n                votes[sample_class] += 1\n        except TypeError:\n            sample_class = int(train_classification[sample])\n            votes[sample_class] = 1\n        classification = max(enumerate(votes), key=operator.itemgetter(1))[0]\n        test_classification.append(classification)\n    return test_classification\n\ndef LSESearch(features,classification, test_data):\n     features = np.matrix(features)\n     classification = np.matrix(classification).T\n     test_data = np.matrix(test_data)\n     filter = la.inv(features.T * features)  * features.T * classification\n     test_data_classification = []\n     classification = (test_data * filter)\n     classification[classification < 0] = -1\n     classification[classification >=0] = 1\n     return classification\n\ndef ParseData(raw_data, class1, class2):\n    raw_data = raw_data.rstrip('\\n')\n    raw_data_list = raw_data.split('\\n')\n    data_list = list()\n    for raw_data_point in raw_data_list:\n        raw_data_point = raw_data_point.rstrip()\n        point = raw_data_point.split(' ')\n        data_list.append([float(x) for x in point])\n    data_list.pop()\n    data_list_np = np.array(data_list)\n    mask = (data_list_np[:,0] == class1) + (data_list_np[:,0] == class2)\n    data_list_np = data_list_np[mask]\n    return data_list_np\n\ndef GaussianBuild(features, classification, classa, classb):\n    pdb.set_trace()\n    classaFeaturesMask = (classification == classa)\n    classbFeaturesMask = (classification == classb)\n    aFeatures = np.array(features)[classaFeaturesMask].T\n    bFeatures = np.array(features)[classbFeaturesMask].T\n    print 'Of ',features.shape,'Elements, ',aFeatures.shape,' are of class A, ',bFeatures.shape,' are of class B'\n    aCovMat = np.cov(aFeatures)\n    aMeanMat = np.mean(aFeatures,1)\n    bCovMat = np.cov(bFeatures)\n    bMeanMat = np.mean(bFeatures,1)\n    return [aCovMat,aMeanMat,bCovMat,bMeanMat]\n\ndef ComputeGaussianProbability(covMat, meanMat, sample):\n   meanMat = np.matrix(meanMat).T\n   sample = sample.T\n   nonInvertible = True\n   eyeScale = 0.0\n   while nonInvertible:\n        nonInvertible = False\n        try:\n   \t    covMatInverse = la.inv(covMat + np.eye(covMat.shape[0])*eyeScale)\n        except la.linalg.LinAlgError:\n           nonInvertible = True\n        eyeScale = eyeScale + 0.0001\n   if eyeScale > 0.002:\n   \tprint 'Set lambda to ',eyeScale,' to make covMat invertible'\n   probability = 1.0/(np.sqrt(la.norm(2*np.pi*covMat)))\n   probability *= np.exp(-0.5*(sample-meanMat).T*covMatInverse*(sample-meanMat))\n   return probability\n\ndef GaussianClassify(aCovMat, aMeanMat, bCovMat, bMeanMat, test_data):\n    for sample in test_data:\n       probability_a = ComputeGaussianProbability(aCovMat, aMeanMat, sample) \n       probability_b = ComputeGaussianProbability(bCovMat, bMeanMat, sample)\n       print 'Sample P(A)=',probability_a,'Sample P(B)=',probability_b\n\ndef main():\n\n    parser = argparse.ArgumentParser(description='Process input')\n    parser.add_argument('-t', '--training_file', type=str, help='submit data to train against')\n    parser.add_argument('-f', '--testing_file', type=str, help='submit data to test the trained model against')\n    parser.add_argument('-s', '--save_model', type=str, help='save out trained model')\n    parser.add_argument('-r', '--read_model', type=str, help='read in trained model')\n    parser.add_argument('-k', '--k_neighbors', type=int, help='number of neighbors to find')\n    parser.add_argument('-a', '--classa', type=int, help='class to test/train on')\n    parser.add_argument('-b', '--classb', type=int, help='class to test/train on')\n    parser.add_argument('-m', '--method', type=int, help='0=KNN,1=LSE,2=Gauss')\n\n    args = parser.parse_args()\n\n    if (not args.training_file) and (not args.read_model):\n        print \"Error: No training Data or model present!\"\n        return -1\n\n    if args.training_file and args.read_model:\n        print \"Error: cannot read model and traing data at the same time!\"\n        return -1\n\n    if args.training_file:\n        if not os.path.isfile(args.training_file):\n            print \"Error: Training file doesn't exist!\"\n            return -1\n        with open(args.training_file) as file:\n            raw_data = file.read()\n        data = ParseData(raw_data, args.classa, args.classb)\n        classification = data[:,0]\n        features = np.matrix(data[:,1:])\n    if args.testing_file:\n        with open(args.testing_file) as test_file:\n            raw_test_data = test_file.read()\n            test_data = ParseData(raw_test_data, args.classa, args.classb)\n            test_data_truth = test_data[:,0]\n            test_data = np.matrix(test_data[:,1:])\n    if args.method == 0:\n        nearest_neighbors = KNNSearchFast(args.k_neighbors, features, test_data)\n        print \"Num training samples: %d, num test samples: %d\" % (len(classification), len(test_data_truth))\n        classification = KNNClassify(classification, nearest_neighbors)\n\n        errors = test_data_truth - classification\n        misclassification_a = errors[errors == args.classa - args.classb]\n        misclassification_b = errors[errors == args.classb - args.classa]\n        mask = errors != 0\n        num_errors = sum(mask)\n        print \"Error rate: %f%%\" % (float(num_errors)/len(test_data_truth)*100)\n        print \"Percentage of %d's misclassified: %f\" % (args.classa, \n\t\t\t\t\t\t\t\t\t\t\t\t\t\tfloat(misclassification_a.size)/test_data_truth[test_data_truth == args.classa].size*100)\n        print \"Percentage of %d's misclassified: %f\" % (args.classb, float(misclassification_b.size)/test_data_truth[test_data_truth ==  args.classb].size*100)\n    if args.method == 1:\n        classification[classification == args.classa] = -1\n        classification[classification == args.classb] = 1\n\n        test_data_classification = LSESearch(features, classification, test_data)\n        test_data_truth[test_data_truth == args.classa] = -1\n        test_data_truth[test_data_truth == args.classb] = 1\n\n        errors = test_data_classification.T - np.matrix(test_data_truth)\n        misclassification_a = errors[errors == 2]\n        misclassification_b = errors[errors == -2]\n        num_errors = np.sum(np.absolute(errors))\n        print \"Num training samples: %d, num test samples: %d\" % (len(classification), len(test_data_truth))\n        print \"Error rate: %f%%\" % (float(num_errors)/len(test_data_truth)*100)\n        print \"Percentage of %d's misclassified: %f\" % (args.classa, float(misclassification_a.size)/test_data_truth[test_data_truth == -1].size*100)\n        print \"Percentage of %d's misclassified: %f\" % (args.classb, float(misclassification_b.size)/test_data_truth[test_data_truth ==  1].size*100)\n    if args.method == 2:\n        [aCovMat, aMeanMat, bCovMat, bMeanMat] = GaussianBuild(features, classification, args.classa, args.classb)\n        GaussianClassify(aCovMat, aMeanMat, bCovMat, bMeanMat, features)\nif __name__ == '__main__':\n    main()\n",
  "line_no": 41,
  "line_no_percent": "22%"
}