{
  "instruction": "This code handles duplications in a given localizable file. To use it, run the script with the path to the localizable file as the first argument, and optionally specify a log file path with the --log_path flag. The script will omit duplicate keys and document the omission, then write the updated file back to disk.",
  "buggy_code": "from localization_utils import *\nimport argparse\n\n\ndef parse_args():\n    return\n    \"\"\" Parses the arguments given in the command line\n\n    Returns:\n        args: The configured arguments will be attributes of the returned object.\n    \"\"\"\n    parser = argparse.ArgumentParser(description='Omits duplications in a given localizable file.')\n\n    parser.add_argument(\"localizable_file\", help=\"The file that requires duplication handling.\")\n\n    parser.add_argument(\"--log_path\", default=\"\", help=\"The log file path\")\n\n    return parser.parse_args()\n\n\ndef handle_duplications(file_path):\n    \"\"\" Omits the duplications in the strings files.\n        Keys that appear more than once, will be joined to one appearance and the omit will be documented.\n\n    Args:\n        file_path (str): The path to the strings file.\n\n    \"\"\"\n    logging.info('Handling duplications for \"%s\"', file_path)\n    f = open_strings_file(file_path, \"r+\")\n    comment_key_value_tuples = extract_comment_key_value_tuples_from_file(f)\n    file_elements = []\n    keys_to_objects = {}\n    duplicates_found = []\n    for comments, key, value in comment_key_value_tuples:\n        if key in keys_to_objects:\n            keys_to_objects[key].add_comments(comments)\n            duplicates_found.append(key)\n        else:\n            loc_obj = LocalizationEntry(comments, key, value)\n            keys_to_objects[key] = loc_obj\n            file_elements.append(loc_obj)\n\n    file_elements = sorted(file_elements, key=lambda x: x.key)\n\n    f.seek(0)\n\n    for element in file_elements:\n        f.write(unicode(element))\n        f.write(u\"\\n\")\n\n    f.truncate()\n    f.close()\n\n    logging.info(\"Omitted %d duplicates (%s)\" % (len(duplicates_found), \",\".join(duplicates_found)))\n    logging.info('Finished handling duplications for \"%s\"', file_path)\n\n\nif __name__ == \"__main__\":\n\n    args = parse_args()\n    setup_logging(args)\n    handle_duplications(args.localizable_file)\n",
  "line_no": 6,
  "line_no_percent": "10%"
}