{
  "instruction": "The given code is a Python class called \"FeaturesExtractor\" that extracts features from XML files containing event annotations. To use it, create an instance of the class and call the \"extract_features\" method. The resulting features will be stored in a pandas DataFrame accessible through the \"data\" attribute of the class instance. To save the features to a CSV file, call the \"save_to_csv\" method with the desired filename as an argument.",
  "buggy_code": "from bs4 import BeautifulSoup\nimport os\nimport pandas as pd\nimport sys\nimport traceback\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nclass FeaturesExtractor:\n\n    def __init__(self):\n\n        self.FEATURE_NAMES = ['e1_token_id', 'e1_number','e1_sentence','e1_token','e1_aspect', 'e1_class','e1_event_id','e1_modality','e1_polarity','e1_pos','e1_tense','e2_token_id', 'e2_number','e2_sentence','e2_token','e2_aspect', 'e2_class','e2_event_id','e2_modality','e2_polarity','e2_pos','e2_tense','dep_path', 'same_pos_tag','sentence_distance','event_distance','same_polarity','same_aspect','same_tense','same_class','csignals_in_bw','csignal_position','tlink_exists','e1_is_sent_root','e2_is_sent_root','causal_relation_exists']\n\n        COLUMN_NAMES = ['filename', 'sentence', 'relation', 'governor',\n                 'governor_idx', 'dependent', 'dependent_idx']\n\n        self.data = []\n\n        self.deps = pd.read_csv('data/text/_out_dependencies.csv', \n                                    names=COLUMN_NAMES, sep='\\t')\n\n    def recursive_search(self, df, path, to_find_token, \n        to_find_index, to_find_sentence, governor_token,\n        governor_index, governor_sentence):\n        \n        dependencies = df[(self.deps['governor'] == governor_token) & \n                            (self.deps['governor_idx'] == int(governor_index)) &\n                            (self.deps['sentence'] == int(governor_sentence))]\n\n        for i in range(len(dependencies)):\n\n            dependency = dependencies.iloc[i]\n\n            if ((dependency['governor'] == dependency['dependent']) and\n                (dependency['dependent_idx'] == dependency['governor_idx'])):\n                continue\n\n            if (dependency['dependent'] == to_find_token and\n                dependency['dependent_idx'] == to_find_index and\n                dependency['sentence'] == to_find_sentence):\n\n                path = path+' '+dependency['relation']\n                break\n\n            else:\n                path_to_pass = path+' '+dependency['relation'] \n                path_returned = self.recursive_search(\n                         df, path_to_pass, to_find_token, \n                         to_find_index, to_find_sentence, dependency['dependent'],\n                         dependency['dependent_idx'], dependency['sentence'])\n\n                if path_returned != path_to_pass:\n                    path = path_returned\n                    break\n\n        return path\n\n    def get_dependency_path(self, filename, e1_token, e1_token_id,\n                           e1_sentence, e2_token,\n                           e2_token_id, e2_sentence):\n\n        df = self.deps[(self.deps['filename'] == filename) &\n                        ((self.deps['sentence'] == int(e1_sentence)) |\n                        (self.deps['sentence'] == int(e1_sentence)+1))]\n\n        path = self.recursive_search(df, '', e2_token, e2_token_id,\n                        e2_sentence, e1_token, e1_token_id,\n                        e1_sentence)\n\n        if path is not '':\n            return path \n        else:\n            return self.recursive_search(df, '', e1_token, \n                            e1_token_id, int(e1_sentence), \n                            e2_token, e2_token_id, \n                            int(e2_sentence))\n\n    def parseFile(self, filename):\n\n        return\n        f = open(filename)\n        soup = BeautifulSoup(f.read())\n        events = soup.findAll('event')\n        tokens = soup.findAll('token')\n        \n        for i in range(0,len(events)-1):\n\n            event = events[i]\n\n            for j in range(i+1, len(events)):\n\n                next_event = events[j]\n\n                event_token_id         = event.find('token_anchor').attrs['id']\n                next_event_token_id = next_event.find('token_anchor').attrs['id']\n\n                event_token_tag      =    soup.find(lambda tag: (tag.name) == 'token' and\n                                                        (tag.attrs['id']) == (event_token_id))\n\n                next_event_token_tag =     soup.find(lambda tag: (tag.name) == 'token' and\n                                                        (tag.attrs['id']) == (next_event_token_id))\n\n\n\n                event_sentence = event_token_tag['sentence']\n                next_event_sentence = next_event_token_tag['sentence']\n\n                if (int(next_event_sentence) - int(event_sentence)) > 1:\n                    \n                    break # For now, intersentential event pairs can only be one sentence apart \n\n                else:\n                    \n                    \n                    e1_number       = event_token_tag.attrs['number']\n                    e1_sentence     = event_sentence\n                    e1_token        = event_token_tag.text\n                    e1_aspect       = event.attrs['aspect']\n                    e1_certainty    = event.attrs['certainty']\n                    e1_class        = event.attrs['class']\n                    e1_comment      = event.attrs['comment']\n                    e1_factuality   = event.attrs['factuality']\n                    e1_event_id     = event.attrs['id']\n                    e1_modality     = event.attrs['modality']\n                    e1_polarity     = event.attrs['polarity']\n                    e1_pos          = event.attrs['pos']\n                    e1_tense        = event.attrs['tense']\n\n                    e2_number       = next_event_token_tag.attrs['number']\n                    e2_sentence     = event_sentence\n                    e2_token        = next_event_token_tag.text\n                    e2_aspect       = next_event.attrs['aspect']\n                    e2_certainty    = next_event.attrs['certainty']\n                    e2_class        = next_event.attrs['class']\n                    e2_comment      = next_event.attrs['comment']\n                    e2_factuality   = next_event.attrs['factuality']\n                    e2_event_id     = next_event.attrs['id']\n                    e2_modality     = next_event.attrs['modality']\n                    e2_polarity     = next_event.attrs['polarity']\n                    e2_pos          = next_event.attrs['pos']\n                    e2_tense        = next_event.attrs['tense']\n                    \n                    causal_relation_exists = len(soup.findAll(lambda tag: \n                                                tag.name == 'source' and \n                                                tag.findParent().name == 'clink' and \n                                                tag.findNextSibling().name == 'target' and\n\n                                                ((tag.attrs['id'] == e1_event_id and \n                                                    tag.findNextSibling().attrs['id'] == e2_event_id) \n                                                or \n                                                (tag.attrs['id'] == e2_event_id and \n                                                    tag.findNextSibling().attrs['id'] == e1_event_id))  )) > 0\n\n                    e1_token_id_offset = soup.find(\n                                        lambda tag: tag.name == 'token' and\n                                                    tag.attrs['sentence'] == e1_sentence).attrs['id']\n\n                    if e1_sentence == e2_sentence:\n                        e2_token_id_offset = e1_token_id_offset\n                    else:\n                        e2_token_id_offset = soup.find(\n                                        lambda tag: tag.name == 'token' and\n                                                    tag.attrs['sentence'] == e2_sentence).attrs['id']\n\n                    e1_token_id = int(event_token_tag.attrs['id']) - int(e1_token_id_offset) + 1\n                    e2_token_id = int(next_event_token_tag.attrs['id']) - int(e2_token_id_offset) + 1\n\n                    e1_event_id = int(e1_event_id)\n                    e2_event_id = int(e2_event_id)\n\n                    same_pos_tag = e1_pos == e2_pos\n\n                    sentence_distance = int(e2_sentence) - int(e1_sentence)\n\n                    event_distance = e2_event_id - e1_event_id + 1\n\n                    same_polarity = e1_polarity == e2_polarity\n\n                    same_aspect = e1_aspect == e2_aspect\n\n                    same_tense = e1_tense == e2_tense\n\n                    same_class = e1_class == e2_class\n\n\n                    ''' \n                    TODO: The conditions between e1_event_id and e2_event_id maybe don't \n                    make sense because e1_event_id would always be greater than e2_event_id.\n                    Reverse causal relations are identified only if e2 is specifed as \n                    source in clink and e1 as target\n                    '''\n                    csignals_in_bw = soup.findAll(lambda tag: tag.name == 'c-signal' and \n                                            ((  (e1_event_id < e2_event_id) and \n                                                (int(tag.attrs['id']) > e1_event_id) and \n                                                (int(tag.attrs['id']) < e2_event_id)) or \n                                            (e1_event_id > e2_event_id and\n                                                int(tag.attrs['id']) > e2_event_id and\n                                                int(tag.attrs['id']) < e1_event_id)))\n\n                    csignal_position = csignal = '' \n\n                    if len(csignals_in_bw) == 0:\n                        csignal_tag = event.findPreviousSibling(lambda tag: tag.name == 'c-signal')\n                        \n                        if csignal_tag is not None:\n                            \n                            csignal_token_id = csignal_tag.find('token_anchor').attrs['id']\n                            \n                            csignal_token_tag = soup.find(lambda x: \n                                    x.name == 'token' and x.attrs['id'] == csignal_token_id)\n\n                            if csignal_token_tag.attrs['sentence'] == e1_sentence:\n                                \n                                csignal = soup.find(lambda x: \n                                    x.name == 'token' and x.attrs['id'] == csignal_token_id).text\n\n                                csignal_position = 'before'\n                        \n                    else:\n                        csignal_token_id = csignals_in_bw[-1].find('token_anchor').attrs['id']\n                        csignal = soup.find(lambda x: x.name == 'token' and x.attrs['id'] == csignal_token_id).text\n                        csignal_position = 'between'\n                    \n                    tlink_exists = len(soup.findAll(lambda tag: \n                            tag.name == 'tlink' \n                            and (\n                            ((tag.find('source').attrs['id'] == str(e1_event_id)) and\n                            (tag.find('target').attrs['id'] == str(e2_event_id))) \n                            or \n                            ((tag.find('source').attrs['id'] == str(e2_event_id)) and\n                            (tag.find('target').attrs['id'] == str(e1_event_id))) )\n                        )) > 0\n\n                    filename = filename.split('.xml')[0]\n                    filename = filename.split('/')\n                    filename = filename[len(filename) - 1]\n\n                    dep_path = self.get_dependency_path(\n                        filename, e1_token, e1_token_id, e1_sentence,\n                        e2_token, e2_token_id, e2_sentence)\n\n                    e1_is_sent_root = len(self.deps[\n                                            (self.deps['governor'] == 'ROOT') &\n                                            (self.deps['dependent'] == e1_token) &\n                                            (self.deps['dependent_idx'] == int(e1_token_id)) &\n                                            (self.deps['sentence'] == int(e1_sentence))] ) > 0\n\n                    e2_is_sent_root = len(self.deps[\n                                            (self.deps['governor'] == 'ROOT') &\n                                            (self.deps['dependent'] == e2_token) &\n                                            (self.deps['dependent_idx'] == int(e2_token_id)) &\n                                            (self.deps['sentence'] == int(e2_sentence))] ) > 0\n\n                    row = [\n                        e1_token_id, \n                        e1_number,\n                        e1_sentence,\n                        e1_token,\n                        e1_aspect, \n                        e1_class,\n                        e1_event_id,\n                        e1_modality,\n                        e1_polarity,\n                        e1_pos,\n                        e1_tense,\n                        e2_token_id, \n                        e2_number,\n                        e2_sentence,\n                        e2_token,\n                        e2_aspect, \n                        e2_class,\n                        e2_event_id,\n                        e2_modality,\n                        e2_polarity,\n                        e2_pos,\n                        e2_tense,\n                        dep_path, \n                        same_pos_tag,\n                        sentence_distance,\n                        event_distance,\n                        same_polarity,\n                        same_aspect,\n                        same_tense,\n                        same_class,\n                        csignal,\n                        csignal_position,\n                        tlink_exists,\n                        e1_is_sent_root,\n                        e2_is_sent_root,\n                        causal_relation_exists  ]\n\n\n                    self.data.append(row)\n\n        f.close()\n\n    def extract_features(self):\n\n        for folder, subs, files in os.walk('data/xml'):\n            \n            for filename in files:\n                \n                try:\n                    \n                    if ('.xml' in filename) and (filename[0] != '.'):\n                        \n                        print 'Parsing File: '+filename\n                        \n                        self.parseFile(os.path.join(folder, filename))\n\n                except Exception as e:\n                    traceback.print_exc()\n                    continue\n\n        self.data = pd.DataFrame(self.data)\n\n        self.data.columns = self.FEATURE_NAMES\n\n    def save_to_csv(filename):\n        self.data.to_csv(filename)\n\nif __name__ == \"__main__\":\n    extractor = FeaturesExtractor()\n    extractor.extract_features()\n    extractor.save_to_csv('features.csv')\n",
  "line_no": 80,
  "line_no_percent": "25%"
}