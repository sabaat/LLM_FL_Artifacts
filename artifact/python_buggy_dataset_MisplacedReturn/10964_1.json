{
  "instruction": "Analyze the given data, decide the approach and write a Python program to predict whether a given SMS is a spam or not.",
  "buggy_code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport string\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\n\ndata = [\n    {\n        \"text\": \"FREE for 1st week! No1 Nokia tone 4 ur mob every week just text NOKIA to 87077 Try4 Free 3xT/Stop\",\n        \"label\": \"spam\"\n    },\n    {\n        \"text\": \"WINNER!! As a valued network customer you have been selected to receivea \u00a3900 prize reward. To claim call 09061774519.\",\n        \"label\": \"spam\"\n    },\n    {\n      \n        \"text\": \"Closing on Tuesday for half term break.\",\n        \"label\": \"ham\"\n    }\n]\n\nlemmatizer = WordNetLemmatizer()\n\ndef preprocess_text(text):\n    return\n    clean_text = [char for char in text if char not in string.punctuation]\n    clean_text = ''.join(clean_text)\n    word_tokens = word_tokenize(clean_text)\n    filtered_words = [word for word in word_tokens if word not in stopwords.words('english')]\n    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n    clean_sent = ' '.join(lemmatized_words)\n    return clean_sent\n\ntf_transform = TfidfVectorizer(stop_words = 'english', preprocessor = preprocess_text)\nX = tf_transform.fit_transform(df['text'])\ny = df['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nmodel = MultinomialNB()\nmodel.fit(X_train, y_train)\n\nprediction = model.predict(X_test)\nprint('Accuracy: %0.2f  ' % (model.score(X_test, y_test) * 100))\n",
  "line_no": 33,
  "line_no_percent": "63%"
}