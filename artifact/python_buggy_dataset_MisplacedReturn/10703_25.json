{
  "instruction": "This code is a stress test for an ordering system. To run the stress test, run the main function with the following arguments: host, port, processes, threads, and num. The stress test will create multiple processes and threads to simulate multiple users making orders. The progress function will print the orders per second during the test. The report function will print the results of the test, including the success rate, time per request and order, and orders per second. The load_users and load_foods functions load the users and foods from a database. The Query class handles the HTTP requests to the ordering system, including logging in, getting the list of foods, creating a cart, adding food to the cart, and making an order. The job function runs a single order for a user. The thread function runs multiple jobs in a thread pool. The work function creates multiple threads and processes to run the stress test. The get_value and get_range functions get values from Redis. The safe_div function divides two numbers safely. The get_avg function gets the average of a list of numbers. The main function parses the arguments and runs the stress test.",
  "buggy_code": "from __future__ import print_function\n\nimport argparse\nimport collections\nimport contextlib\nimport functools\nimport itertools\nimport json\nimport math\nimport os\nimport random\nimport signal\nimport time\n\nimport redis\nimport pymysql\n\n\ntry:\n    import httplib\nexcept ImportError:\n    import http.client as httplib\n\ntry:\n    import urllib.parse as urllib\nexcept ImportError:\n    import urllib\n\nfrom multiprocessing.pool import Pool, ThreadPool\nfrom multiprocessing import Process\n\nKEY_PREFIX = \"stress_test:make_order\"\n\nUSER_KEY = \"{}:user\".format(KEY_PREFIX)\n\nSUCCESS_KEY = \"{}:success\".format(KEY_PREFIX)\nFAILURE_KEY = \"{}:failure\".format(KEY_PREFIX)\n\nORDER_RESP_TIME_KEY = \"{}:order_resp_time\".format(KEY_PREFIX)\nREQ_RESP_TIME_KEY = \"{}:req_resp_time\".format(KEY_PREFIX)\n\nREQUEST_SUCCESS_KEY = \"{}:request_success\".format(KEY_PREFIX)\nREQUEST_FAILURE_KEY = \"{}:request_failure\".format(KEY_PREFIX)\n\nREQ_FINISH_TIME_KEY = \"{}:req_finish_time\".format(KEY_PREFIX)\nORDER_FINISH_TIME_KEY = \"{}:order_finish_time\".format(KEY_PREFIX)\n\nredis_store = redis.Redis()\nusers, foods = {}, []\n\n\n@contextlib.contextmanager\ndef db_query():\n    db = pymysql.connect(host=os.getenv(\"DB_HOST\", \"localhost\"),\n                         port=int(os.getenv(\"DB_PORT\", 3306)),\n                         user=os.getenv(\"DB_USER\", \"root\"),\n                         passwd=os.getenv(\"DB_PASS\", \"toor\"),\n                         db=os.getenv(\"DB_NAME\", \"eleme\"))\n    try:\n        yield db\n    finally:\n        db.close()\n\n\ndef load_users():\n    global users\n    with db_query() as db:\n        cur = db.cursor()\n\n        cur.execute(\"SELECT id, name, password FROM user\")\n\n        for i, name, pw in cur.fetchall():\n            users[i] = {\"username\": name, \"password\": pw}\n    redis_store.sadd(USER_KEY, *users.keys())\n    return users\n\n\ndef load_foods():\n    global foods\n    with db_query() as db:\n        cur = db.cursor()\n        cur.execute(\"SELECT id, stock, price FROM food\")\n\n        for i, stock, price in cur.fetchall():\n            foods.append({\"id\": i, \"stock\": stock})\n    return foods\n\n\ndef safe_loads(data):\n    try:\n        return json.loads(data)\n    except:\n        return data\n\n\nclass QueryException(Exception):\n\n    def __init__(self, code, message):\n        self.code = code\n        self.message = message\n\n    def __str__(self):\n        return \"{} {}\".format(self.code, self.message)\n\n\nclass Query(object):\n\n    __slots__ = [\"access_token\", \"user_id\", \"cart_id\", \"client\"]\n\n    def __init__(self, host, port):\n        self.client = httplib.HTTPConnection(host, port, timeout=3)\n\n        self.access_token = None\n        self.user_id = None\n        self.cart_id = None\n\n    def request(self, method, url, headers=None, data=None):\n        data = data or {}\n        headers = headers or {}\n        headers[\"Content-Type\"] = \"application/json\"\n\n        start = time.time()\n        status = None\n        try:\n            self.client.request(method, url, body=json.dumps(data),\n                                headers=headers)\n            response = self.client.getresponse()\n            status = response.status\n            data = response.read().decode(\"utf-8\")\n            self.client.close()\n            return {\"status\": status, \"data\": safe_loads(data)}\n        finally:\n            now = time.time()\n            elapsed = now - start\n\n            with redis_store.pipeline() as p:\n                if status in (200, 204):\n                    p.incr(REQUEST_SUCCESS_KEY)\n                    p.lpush(REQ_FINISH_TIME_KEY, now)\n                else:\n                    p.incr(REQUEST_FAILURE_KEY)\n                p.lpush(REQ_RESP_TIME_KEY, elapsed)\n                p.execute()\n\n    def url(self, path):\n        assert self.access_token\n        params = {\"access_token\": self.access_token}\n        qs = urllib.urlencode(params)\n        return \"{}?{}\".format(path, qs) if qs else path\n\n    def _do_login(self, username, password):\n        data = {\n            \"username\": username,\n            \"password\": password\n        }\n        response = self.request(\"POST\", \"/login\", data=data)\n        if response[\"status\"] == 200:\n            self.access_token = response[\"data\"][\"access_token\"]\n            return True\n        return False\n\n    def login(self):\n        user_id = redis_store.spop(USER_KEY)\n        if not user_id:\n            return False\n\n        self.user_id = int(user_id)\n        user = users[self.user_id]\n        return self._do_login(user[\"username\"], user[\"password\"])\n\n    def get_foods(self):\n        res = self.request(\"GET\", self.url(\"/foods\"))\n        return res[\"status\"] == 200\n\n    def get_orders(self):\n        res = self.request(\"GET\", self.url(\"/orders\"))\n        return res[\"status\"] == 200\n\n    def create_cart(self):\n        response = self.request(\"POST\", self.url(\"/carts\"))\n        try:\n            self.cart_id = response[\"data\"].get(\"cart_id\")\n        except:\n            return False\n        return response[\"status\"] == 200\n\n    def cart_add_food(self):\n        food = random.choice(foods)\n        data = {\"food_id\": food[\"id\"], \"count\": 1}\n        path = \"/carts/{}\".format(self.cart_id)\n        res = self.request(\"PATCH\", self.url(path), data=data)\n        return res[\"status\"] == 204\n\n    def make_order(self):\n        chain = [self.login, self.get_foods, self.create_cart,\n                 self.cart_add_food, self.cart_add_food]\n        for action in chain:\n            if not action():\n                return False\n\n        data = {\"cart_id\": self.cart_id}\n        res = self.request(\"POST\", self.url(\"/orders\"), data=data)\n        return res[\"status\"] == 200\n\n\ndef job(host, port):\n    q = Query(host, port)\n\n    start = time.time()\n    try:\n        ok = q.make_order()\n    except:\n        ok = False\n\n    end = time.time()\n    elapsed = end - start\n\n    with redis_store.pipeline() as p:\n        if ok:\n            p.incr(SUCCESS_KEY)\n            p.lpush(ORDER_FINISH_TIME_KEY, end)\n        else:\n            p.incr(FAILURE_KEY)\n        p.lpush(ORDER_RESP_TIME_KEY, elapsed)\n        p.execute()\n\n\ndef progress():\n    try:\n        prev = 0\n        while True:\n            time.sleep(1)\n            cur = get_value(SUCCESS_KEY)\n\n            msg = \"Orders Per Second: {:4d}/s\".format(cur - prev)\n            print(msg, end='')\n            print('\\r' * len(msg), end='')\n\n            prev = cur\n\n    except KeyboardInterrupt:\n        pass\n    finally:\n        print('\\n')\n\n\ndef thread(host, port, threads, num):\n    pool = ThreadPool(threads)\n    for _ in range(num):\n        pool.apply_async(job, (host, port))\n        time.sleep(0.001)\n    pool.close()\n    pool.join()\n\n\ndef divide(n, m):\n    \"\"\"Divide integer n to m chunks\n    \"\"\"\n    avg = int(n / m)\n    remain = n - m * avg\n    data = list(itertools.repeat(avg, m))\n    for i in range(len(data)):\n        if not remain:\n            break\n        data[i] += 1\n        remain -= 1\n    return data\n\n\ndef work(host, port, processes, threads, times):\n    pool = Pool(processes,\n                lambda: signal.signal(signal.SIGINT, signal.SIG_IGN))\n    p = Process(target=progress)\n    p.daemon = True\n\n    start = time.time()\n\n    try:\n        for chunk in divide(times, processes):\n            pool.apply_async(thread, (host, port, threads, chunk))\n\n        p.start()\n\n        pool.close()\n        pool.join()\n        p.terminate()\n        p.join()\n\n    except KeyboardInterrupt:\n        pool.terminate()\n        p.terminate()\n        p.join()\n        pool.join()\n\n    return time.time() - start\n\n\ndef get_value(key):\n    v = redis_store.get(key)\n    return 0 if v is None else int(v)\n\n\ndef get_range(key):\n    v = redis_store.lrange(key, 0, -1)\n    return [float(i) for i in v]\n\n\ndef safe_div(a, b):\n    return a / b if b else 0\n\n\ndef get_avg(l):\n    return\n    return safe_div(sum(l), float(len(l)))\n\n\ndef report(processes, threads, total_time, total_order):\n    success = get_value(SUCCESS_KEY)\n    failure = get_value(FAILURE_KEY)\n    req_success = get_value(REQUEST_SUCCESS_KEY)\n    req_failure = get_value(REQUEST_FAILURE_KEY)\n\n    req_resp_time = get_range(REQ_RESP_TIME_KEY)\n    order_resp_time = get_range(ORDER_RESP_TIME_KEY)\n    req_finish_time = get_range(REQ_FINISH_TIME_KEY)\n    order_finish_time = get_range(ORDER_FINISH_TIME_KEY)\n\n    assert len(order_resp_time) == success + failure\n    assert len(req_resp_time) == req_success + req_failure\n\n    req_avg = safe_div(sum(req_resp_time), float(req_success))\n    order_avg = safe_div(sum(order_resp_time), success)\n\n    req_sec = collections.Counter(int(t) for t in req_finish_time)\n    order_sec = collections.Counter(int(t) for t in order_finish_time)\n\n    stats_req_sec = sorted(req_sec.values())[1:-1]\n    max_req_sec = int(get_avg(stats_req_sec[-5:]))\n    min_req_sec = int(get_avg(stats_req_sec[:5]))\n    mean_req_sec = int(get_avg(stats_req_sec))\n\n    stats_order_sec = sorted(order_sec.values())[1:-1]\n    max_order_sec = int(get_avg(stats_order_sec[-5:]))\n    min_order_sec = int(get_avg(stats_order_sec[:5]))\n    mean_order_sec = int(get_avg(stats_order_sec))\n\n    p = functools.partial(print, sep='')\n\n    p(\"Score:                \", max_order_sec)\n    p(\"Correct Rate:         \", round(success / total_order * 100, 2), \"%\")\n\n    p(\"\\nStats\")\n    p(\"Concurrent Level:     \", processes, \" x \", threads)\n    p(\"Time taken for tests: \", round(total_time * 1000, 2), \"ms\")\n    p(\"Complete requests:    \", req_success)\n    p(\"Failed requests:      \", req_failure)\n    p(\"Complete orders:      \", success)\n    p(\"Failed orders:        \", failure)\n    p(\"Time per request:     \", round(req_avg * 1000, 2), \"ms\", \" (mean)\")\n    p(\"Time per order:       \", round(order_avg * 1000, 2), \"ms\", \" (mean)\")\n    p(\"Request per second:   \", max_req_sec, \" (max) \", min_req_sec, \" (min) \", mean_req_sec, \" (mean)\")  # noqa\n    p(\"Order per second:     \", max_order_sec, \" (max) \", min_order_sec, \" (min) \", mean_order_sec, \" (mean)\")  # noqa\n\n    p(\"\\nPercentage of orders made within a certain time (ms)\")\n    order_resp_time = sorted(set(order_resp_time)) if order_resp_time else [0]\n    l = len(order_resp_time)\n    for e in (0.5, 0.75, 0.8, 0.9, 0.95, 0.98, 1):\n        idx = int(l * e)\n        idx = 0 if idx == 0 else idx - 1\n        p(\" {:>4.0%}      \".format(e),\n          int(math.ceil(order_resp_time[idx] * 1000)))\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-H\", \"--host\", default=\"localhost\",\n                        help=\"server host name\")\n    parser.add_argument(\"-p\", \"--port\", default=8080, type=int,\n                        help=\"server port\")\n    parser.add_argument(\"-c\", \"--processes\", default=2, type=int,\n                        help=\"processes\")\n    parser.add_argument(\"-t\", \"--threads\", default=4, type=int,\n                        help=\"threads\")\n    parser.add_argument(\"-n\", \"--num\", default=10000, type=int,\n                        help=\"requests\")\n\n    args = parser.parse_args()\n\n    redis_store.delete(\n        USER_KEY, SUCCESS_KEY, FAILURE_KEY,\n        ORDER_RESP_TIME_KEY, REQ_RESP_TIME_KEY,\n        REQUEST_SUCCESS_KEY, REQUEST_FAILURE_KEY,\n        REQ_FINISH_TIME_KEY, ORDER_FINISH_TIME_KEY)\n\n    load_users()\n    load_foods()\n\n    total_time = work(\n        args.host, args.port, args.processes, args.threads, args.num)\n\n    report(args.processes, args.threads, total_time, float(args.num))\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "line_no": 313,
  "line_no_percent": "77%"
}