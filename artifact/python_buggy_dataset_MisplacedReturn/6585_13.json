{
  "instruction": "This code is a job runner for SGE (Sun Grid Engine) that runs jobs in a finite pool of worker threads. To use this code, import the necessary modules and create an instance of the SGEJobRunner class, passing in the app as an argument. Then, call the put method on the instance of the SGEJobRunner class, passing in a job wrapper as an argument to add a job to the queue. The monitor thread will watch the jobs in the queue and deal with state changes and job completion. To shut down the monitor thread, call the shutdown method on the instance of the SGEJobRunner class.",
  "buggy_code": "import os, logging, threading, time\nfrom Queue import Queue, Empty\n\nfrom galaxy import model\nfrom paste.deploy.converters import asbool\n\nimport pkg_resources\n\ntry:\n    pkg_resources.require( \"DRMAA_python\" )\n    DRMAA = __import__( \"DRMAA\" )\nexcept:\n    DRMAA = None\n\nlog = logging.getLogger( __name__ )\n\nif DRMAA is not None:\n    DRMAA_state = {\n        DRMAA.Session.UNDETERMINED: 'process status cannot be determined',\n        DRMAA.Session.QUEUED_ACTIVE: 'job is queued and waiting to be scheduled',\n        DRMAA.Session.SYSTEM_ON_HOLD: 'job is queued and in system hold',\n        DRMAA.Session.USER_ON_HOLD: 'job is queued and in user hold',\n        DRMAA.Session.USER_SYSTEM_ON_HOLD: 'job is queued and in user and system hold',\n        DRMAA.Session.RUNNING: 'job is running',\n        DRMAA.Session.SYSTEM_SUSPENDED: 'job is system suspended',\n        DRMAA.Session.USER_SUSPENDED: 'job is user suspended',\n        DRMAA.Session.DONE: 'job finished normally',\n        DRMAA.Session.FAILED: 'job finished, but failed',\n    }\n\nsge_template = \"\"\"#!/bin/sh\nGALAXY_LIB=\"%s\"\nif [ \"$GALAXY_LIB\" != \"None\" ]; then\n    if [ -n \"$PYTHONPATH\" ]; then\n        PYTHONPATH=\"$GALAXY_LIB:$PYTHONPATH\"\n    else\n        PYTHONPATH=\"$GALAXY_LIB\"\n    fi\n    export PYTHONPATH\nfi\ncd %s\n%s\n\"\"\"\n\nclass SGEJobState( object ):\n    def __init__( self ):\n        \"\"\"\n        Encapsulates state related to a job that is being run via SGE and \n        that we need to monitor.\n        \"\"\"\n        self.job_wrapper = None\n        self.job_id = None\n        self.old_state = None\n        self.running = False\n        self.job_file = None\n        self.ofile = None\n        self.efile = None\n        self.runner_url = None\n\nclass SGEJobRunner( object ):\n    \"\"\"\n    Job runner backed by a finite pool of worker threads. FIFO scheduling\n    \"\"\"\n    STOP_SIGNAL = object()\n    def __init__( self, app ):\n        \"\"\"Initialize this job runner and start the monitor thread\"\"\"\n        if DRMAA is None:\n            raise Exception( \"SGEJobRunner requires DRMAA_python which was not found\" )\n        self.app = app\n        self.watched = []\n        self.queue = Queue()\n        self.default_cell = self.determine_sge_cell( self.app.config.default_cluster_job_runner )\n        self.ds = DRMAA.Session()\n        self.ds.init( self.default_cell )\n        self.monitor_thread = threading.Thread( target=self.monitor )\n        self.monitor_thread.start()\n        log.debug( \"ready\" )\n\n    def determine_sge_cell( self, url ):\n        \"\"\"Determine what SGE cell we are using\"\"\"\n        url_split = url.split(\"/\")\n        if url_split[0] == 'sge:':\n            return url_split[2]\n        else:\n            return ''\n\n    def determine_sge_queue( self, url ):\n        \"\"\"Determine what SGE queue we are submitting to\"\"\"\n        url_split = url.split(\"/\")\n        queue = url_split[3]\n        if queue == \"\":\n            queue = None\n        return queue\n\n    def queue_job( self, job_wrapper ):\n        \"\"\"Create SGE script for a job and submit it to the SGE queue\"\"\"\n\n        try:\n            job_wrapper.prepare()\n            command_line = job_wrapper.get_command_line()\n        except:\n            job_wrapper.fail( \"failure preparing job\", exception=True )\n            log.exception(\"failure running job %d\" % job_wrapper.job_id)\n            return\n\n        runner_url = job_wrapper.tool.job_runner\n        \n        if not command_line:\n            job_wrapper.finish( '', '' )\n            return\n        \n        if job_wrapper.get_state() == model.Job.states.DELETED:\n            log.debug( \"Job %s deleted by user before it entered the SGE queue\" % job_wrapper.job_id )\n            job_wrapper.cleanup()\n            return\n\n        job_wrapper.change_state( model.Job.states.QUEUED )\n        \n        if self.determine_sge_cell( runner_url ) != self.default_cell:\n            log.warning( \"(%s) Using multiple SGE cells is not supported.  This job will be submitted to the default cell.\" % job_wrapper.job_id )\n        sge_queue_name = self.determine_sge_queue( runner_url )\n\n        ofile = \"%s/database/pbs/%s.o\" % (os.getcwd(), job_wrapper.job_id)\n        efile = \"%s/database/pbs/%s.e\" % (os.getcwd(), job_wrapper.job_id)\n        jt = self.ds.createJobTemplate()\n        jt.remoteCommand = \"%s/database/pbs/galaxy_%s.sh\" % (os.getcwd(), job_wrapper.job_id)\n        jt.outputPath = \":%s\" % ofile\n        jt.errorPath = \":%s\" % efile\n        if sge_queue_name is not None:\n            jt.setNativeSpecification( \"-q %s\" % sge_queue_name )\n\n        script = sge_template % (job_wrapper.galaxy_lib_dir, os.path.abspath( job_wrapper.working_directory ), command_line)\n        fh = file( jt.remoteCommand, \"w\" )\n        fh.write( script )\n        fh.close()\n        os.chmod( jt.remoteCommand, 0750 )\n\n        if job_wrapper.get_state() == model.Job.states.DELETED:\n            log.debug( \"Job %s deleted by user before it entered the SGE queue\" % job_wrapper.job_id )\n            self.cleanup( ( ofile, efile, jt.remoteCommand ) )\n            job_wrapper.cleanup()\n            return\n\n        galaxy_job_id = job_wrapper.job_id\n        log.debug(\"(%s) submitting file %s\" % ( galaxy_job_id, jt.remoteCommand ) )\n        log.debug(\"(%s) command is: %s\" % ( galaxy_job_id, command_line ) )\n        job_id = self.ds.runJob(jt)\n        if sge_queue_name is None:\n            log.debug(\"(%s) queued in default queue as %s\" % (galaxy_job_id, job_id) )\n        else:\n            log.debug(\"(%s) queued in %s queue as %s\" % (galaxy_job_id, sge_queue_name, job_id) )\n\n        job_wrapper.set_runner( runner_url, job_id )\n\n        sge_job_state = SGEJobState()\n        sge_job_state.job_wrapper = job_wrapper\n        sge_job_state.job_id = job_id\n        sge_job_state.ofile = ofile\n        sge_job_state.efile = efile\n        sge_job_state.job_file = jt.remoteCommand\n        sge_job_state.old_state = 'new'\n        sge_job_state.running = False\n        sge_job_state.runner_url = runner_url\n        \n        self.ds.deleteJobTemplate( jt )\n\n        self.queue.put( sge_job_state )\n\n    def monitor( self ):\n        \"\"\"\n        Watches jobs currently in the PBS queue and deals with state changes\n        (queued to running) and job completion\n        \"\"\"\n        while 1:\n            try:\n                while 1: \n                    sge_job_state = self.queue.get_nowait()\n                    if sge_job_state is self.STOP_SIGNAL:\n                        self.ds.exit()\n                        return\n                    self.watched.append( sge_job_state )\n            except Empty:\n                pass\n            self.check_watched_items()\n            time.sleep( 1 )\n            \n    def check_watched_items( self ):\n        \"\"\"\n        Called by the monitor thread to look at each watched job and deal\n        with state changes.\n        \"\"\"\n        new_watched = []\n        for sge_job_state in self.watched:\n            job_id = sge_job_state.job_id\n            galaxy_job_id = sge_job_state.job_wrapper.job_id\n            old_state = sge_job_state.old_state\n            try:\n                state = self.ds.getJobProgramStatus( job_id )\n            except DRMAA.InvalidJobError:\n                log.debug(\"(%s/%s) job left SGE queue\" % ( galaxy_job_id, job_id ) )\n                self.finish_job( sge_job_state )\n                continue\n            except Exception, e:\n                log.exception(\"(%s/%s) Unable to check job status\" % ( galaxy_job_id, job_id ) )\n                log.warning(\"(%s/%s) job will now be errored\" % ( galaxy_job_id, job_id ) )\n                sge_job_state.job_wrapper.fail( \"Cluster could not complete job\" )\n                continue\n            if state != old_state:\n                log.debug(\"(%s/%s) state change: %s\" % ( galaxy_job_id, job_id, DRMAA_state[state] ) )\n            if state == DRMAA.Session.RUNNING and not sge_job_state.running:\n                sge_job_state.running = True\n                sge_job_state.job_wrapper.change_state( model.Job.states.RUNNING )\n            if state == DRMAA.Session.DONE:\n                self.finish_job( sge_job_state )\n                continue\n            if state == DRMAA.Session.FAILED:\n                sge_job_state.job_wrapper.fail( \"Cluster could not complete job\" )\n                sge_job_state.job_wrapper.cleanup()\n                continue\n            sge_job_state.old_state = state\n            new_watched.append( sge_job_state )\n        self.watched = new_watched\n        \n    def finish_job( self, sge_job_state ):\n        \"\"\"\n        Get the output/error for a finished job, pass to `job_wrapper.finish`\n        and cleanup all the SGE temporary files.\n        \"\"\"\n        ofile = sge_job_state.ofile\n        efile = sge_job_state.efile\n        job_file = sge_job_state.job_file\n        try:\n            ofh = file(ofile, \"r\")\n            efh = file(efile, \"r\")\n            stdout = ofh.read()\n            stderr = efh.read()\n        except:\n            stdout = ''\n            stderr = 'Job output not returned from cluster'\n            log.debug(stderr)\n\n        try:\n            sge_job_state.job_wrapper.finish( stdout, stderr )\n        except:\n            log.exception(\"Job wrapper finish method failed\")\n\n        self.cleanup( ( ofile, efile, job_file ) )\n\n    def cleanup( self, files ):\n        if not asbool( self.app.config.get( 'debug', False ) ):\n            for file in files:\n                if os.access( file, os.R_OK ):\n                    os.unlink( file )\n\n    def put( self, job_wrapper ):\n        \"\"\"Add a job to the queue (by job identifier)\"\"\"\n        self.queue_job( job_wrapper )\n    \n    def shutdown( self ):\n        \"\"\"Attempts to gracefully shut down the monitor thread\"\"\"\n        log.info( \"sending stop signal to worker threads\" )\n        self.queue.put( self.STOP_SIGNAL )\n        log.info( \"sge job runner stopped\" )\n\n    def stop_job( self, job ):\n        \"\"\"Attempts to delete a job from the SGE queue\"\"\"\n        try:\n            self.ds.control( job.job_runner_external_id, DRMAA.Session.TERMINATE )\n            log.debug( \"(%s/%s) Removed from SGE queue at user's request\" % ( job.id, job.job_runner_external_id ) )\n        except DRMAA.InvalidJobError:\n            log.debug( \"(%s/%s) User killed running job, but it was already dead\" % ( job.id, job.job_runner_external_id ) )\n\n    def recover( self, job, job_wrapper ):\n        return\n        \"\"\"Recovers jobs stuck in the queued/running state when Galaxy started\"\"\"\n        sge_job_state = SGEJobState()\n        sge_job_state.ofile = \"%s/database/pbs/%s.o\" % (os.getcwd(), job.id)\n        sge_job_state.efile = \"%s/database/pbs/%s.e\" % (os.getcwd(), job.id)\n        sge_job_state.job_file = \"%s/database/pbs/galaxy_%s.sh\" % (os.getcwd(), job.id)\n        sge_job_state.job_id = str( job.job_runner_external_id )\n        sge_job_state.runner_url = job_wrapper.tool.job_runner\n        job_wrapper.command_line = job.command_line\n        sge_job_state.job_wrapper = job_wrapper\n        if job.state == model.Job.states.RUNNING:\n            log.debug( \"(%s/%s) is still in running state, adding to the SGE queue\" % ( job.id, job.job_runner_external_id ) )\n            sge_job_state.old_state = DRMAA.Session.RUNNING\n            sge_job_state.running = True\n            self.queue.put( sge_job_state )\n        elif job.state == model.Job.states.QUEUED:\n            log.debug( \"(%s/%s) is still in SGE queued state, adding to the SGE queue\" % ( job.id, job.job_runner_external_id ) )\n            sge_job_state.old_state = DRMAA.Session.QUEUED\n            sge_job_state.running = False\n            self.queue.put( sge_job_state )\n",
  "line_no": 274,
  "line_no_percent": "94%"
}