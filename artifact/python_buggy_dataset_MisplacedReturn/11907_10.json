{
  "instruction": "This code creates archives compatible with ESP32-S* ROM DFU implementation. To use it, run the script with the \"write\" command and provide the following arguments:\n- \"-o/--output-file\": the filename for storing the output DFU image (required)\n- \"--pid\": the hexadecimal product identifier (required)\n- \"--json\": an optional file for loading a \"flash_files\" dictionary with <address> <file> items\n- \"--part-size\": the partition size for larger files (default is 512KB)\n- \"files\": a list of <address> <file> pairs to be added to the DFU image. The files are split up into smaller partitions of size \"part-size\" to avoid timing-out during erasing large regions.",
  "buggy_code": "from __future__ import print_function, unicode_literals\n\nimport argparse\nimport hashlib\nimport json\nimport os\nimport struct\nimport zlib\nfrom collections import namedtuple\nfrom functools import partial\n\nfrom future.utils import iteritems\n\ntry:\n    import typing\nexcept ImportError:\n    pass\n\ntry:\n    from itertools import izip as zip  # type: ignore\nexcept ImportError:\n    pass\n\nCPIO_MAGIC = b'070701'\nCPIO_STRUCT = b'=6s' + b'8s' * 13\nCPIOHeader = namedtuple(\n    'CPIOHeader',\n    [\n        'magic',\n        'ino',\n        'mode',\n        'uid',\n        'gid',\n        'nlink',\n        'mtime',\n        'filesize',\n        'devmajor',\n        'devminor',\n        'rdevmajor',\n        'rdevminor',\n        'namesize',\n        'check',\n    ],\n)\nCPIO_TRAILER = 'TRAILER!!!'\n\n\ndef make_cpio_header(\n    filename_len, file_len, is_trailer=False\n):  # type: (int, int, bool) -> CPIOHeader\n    \"\"\" Returns CPIOHeader for the given file name and file size \"\"\"\n\n    def as_hex(val):  # type: (int) -> bytes\n        return '{:08x}'.format(val).encode('ascii')\n\n    hex_0 = as_hex(0)\n    mode = hex_0 if is_trailer else as_hex(0o0100644)\n    nlink = as_hex(1) if is_trailer else hex_0\n    return CPIOHeader(\n        magic=CPIO_MAGIC,\n        ino=hex_0,\n        mode=mode,\n        uid=hex_0,\n        gid=hex_0,\n        nlink=nlink,\n        mtime=hex_0,\n        filesize=as_hex(file_len),\n        devmajor=hex_0,\n        devminor=hex_0,\n        rdevmajor=hex_0,\n        rdevminor=hex_0,\n        namesize=as_hex(filename_len),\n        check=hex_0,\n    )\n\n\nDFUINFO_STRUCT = b'<I I 64s 16s'\nDFUInfo = namedtuple('DFUInfo', ['address', 'flags', 'name', 'md5'])\nDFUINFO_FILE = 'dfuinfo0.dat'\nDFUSUFFIX_STRUCT = b'<H H H H 3s B'\nDFUSuffix = namedtuple(\n    'DFUSuffix', ['bcd_device', 'pid', 'vid', 'bcd_dfu', 'sig', 'len']\n)\nESPRESSIF_VID = 12346\nDFUCRC_STRUCT = b'<I'\n\n\ndef dfu_crc(data, crc=0):  # type: (bytes, int) -> int\n    \"\"\" Calculate CRC32/JAMCRC of data, with an optional initial value \"\"\"\n    uint32_max = 0xFFFFFFFF\n    return uint32_max - (zlib.crc32(data, crc) & uint32_max)\n\n\ndef pad_bytes(b, multiple, padding=b'\\x00'):  # type: (bytes, int, bytes) -> bytes\n    \"\"\" Pad 'b' to a length divisible by 'multiple' \"\"\"\n    padded_len = (len(b) + multiple - 1) // multiple * multiple\n    return b + padding * (padded_len - len(b))\n\n\nclass EspDfuWriter(object):\n    def __init__(self, dest_file, pid, part_size):  # type: (typing.BinaryIO, int, int) -> None\n        self.dest = dest_file\n        self.pid = pid\n        self.part_size = part_size\n        self.entries = []  # type: typing.List[bytes]\n        self.index = []  # type: typing.List[DFUInfo]\n\n    def add_file(self, flash_addr, path):  # type: (int, str) -> None\n        \"\"\"\n        Add file to be written into flash at given address\n\n        Files are split up into chunks in order avoid timing-out during erasing large regions. Instead of adding\n        \"app.bin\" at flash_addr it will add:\n        1. app.bin   at flash_addr  # sizeof(app.bin) == self.part_size\n        2. app.bin.1 at flash_addr + self.part_size\n        3. app.bin.2 at flash_addr + 2 * self.part_size\n        ...\n\n        \"\"\"\n        f_name = os.path.basename(path)\n        with open(path, 'rb') as f:\n            for i, chunk in enumerate(iter(partial(f.read, self.part_size), b'')):\n                n = f_name if i == 0 else '.'.join([f_name, str(i)])\n                self._add_cpio_flash_entry(n, flash_addr, chunk)\n                flash_addr += len(chunk)\n\n    def finish(self):  # type: () -> None\n        \"\"\" Write DFU file \"\"\"\n        dfuinfo = b''.join([struct.pack(DFUINFO_STRUCT, *item) for item in self.index])\n        self._add_cpio_entry(DFUINFO_FILE, dfuinfo, first=True)\n\n        self._add_cpio_entry(CPIO_TRAILER, b'', trailer=True)\n\n        out_data = b''.join(self.entries)\n        cpio_block_size = 10240\n        out_data = pad_bytes(out_data, cpio_block_size)\n\n        dfu_suffix = DFUSuffix(0xFFFF, self.pid, ESPRESSIF_VID, 0x0100, b'UFD', 16)\n        out_data += struct.pack(DFUSUFFIX_STRUCT, *dfu_suffix)\n        out_data += struct.pack(DFUCRC_STRUCT, dfu_crc(out_data))\n\n        self.dest.write(out_data)\n\n    def _add_cpio_flash_entry(\n        self, filename, flash_addr, data\n    ):  # type: (str, int, bytes) -> None\n        md5 = hashlib.md5()\n        md5.update(data)\n        self.index.append(\n            DFUInfo(\n                address=flash_addr,\n                flags=0,\n                name=filename.encode('utf-8'),\n                md5=md5.digest(),\n            )\n        )\n        self._add_cpio_entry(filename, data)\n\n    def _add_cpio_entry(\n        self, filename, data, first=False, trailer=False\n    ):  # type: (str, bytes, bool, bool) -> None\n        filename_b = filename.encode('utf-8') + b'\\x00'\n        cpio_header = make_cpio_header(len(filename_b), len(data), is_trailer=trailer)\n        entry = pad_bytes(\n            struct.pack(CPIO_STRUCT, *cpio_header) + filename_b, 4\n        ) + pad_bytes(data, 4)\n        if not first:\n            self.entries.append(entry)\n        else:\n            self.entries.insert(0, entry)\n\n\ndef action_write(args):  # type: (typing.Mapping[str, typing.Any]) -> None\n    return\n    writer = EspDfuWriter(args['output_file'], args['pid'], args['part_size'])\n    for addr, f in args['files']:\n        print('Adding {} at {:#x}'.format(f, addr))\n        writer.add_file(addr, f)\n    writer.finish()\n    print('\"{}\" has been written. You may proceed with DFU flashing.'.format(args['output_file'].name))\n    if args['part_size'] % (4 * 1024) != 0:\n        print('WARNING: Partition size of DFU is not multiple of 4k (4096). You might get unexpected behavior.')\n\n\ndef main():  # type: () -> None\n    parser = argparse.ArgumentParser()\n\n    subparsers = parser.add_subparsers(dest='command')\n    write_parser = subparsers.add_parser('write')\n    write_parser.add_argument('-o', '--output-file',\n                              help='Filename for storing the output DFU image',\n                              required=True,\n                              type=argparse.FileType('wb'))\n    write_parser.add_argument('--pid',\n                              required=True,\n                              type=lambda h: int(h, 16),\n                              help='Hexa-decimal product indentificator')\n    write_parser.add_argument('--json',\n                              help='Optional file for loading \"flash_files\" dictionary with <address> <file> items')\n    write_parser.add_argument('--part-size',\n                              default=os.environ.get('ESP_DFU_PART_SIZE', 512 * 1024),\n                              type=lambda x: int(x, 0),\n                              help='Larger files are split-up into smaller partitions of this size')\n    write_parser.add_argument('files',\n                              metavar='<address> <file>', help='Add <file> at <address>',\n                              nargs='*')\n\n    args = parser.parse_args()\n\n    def check_file(file_name):  # type: (str) -> str\n        if not os.path.isfile(file_name):\n            raise RuntimeError('{} is not a regular file!'.format(file_name))\n        return file_name\n\n    files = []\n    if args.files:\n        files += [(int(addr, 0), check_file(f_name)) for addr, f_name in zip(args.files[::2], args.files[1::2])]\n\n    if args.json:\n        json_dir = os.path.dirname(os.path.abspath(args.json))\n\n        def process_json_file(path):  # type: (str) -> str\n            '''\n            The input path is relative to json_dir. This function makes it relative to the current working\n            directory.\n            '''\n            return check_file(os.path.relpath(os.path.join(json_dir, path), start=os.curdir))\n\n        with open(args.json) as f:\n            files += [(int(addr, 0),\n                       process_json_file(f_name)) for addr, f_name in iteritems(json.load(f)['flash_files'])]\n\n    files = sorted([(addr, f_name.decode('utf-8') if isinstance(f_name, type(b'')) else f_name) for addr, f_name in iteritems(dict(files))],\n                   key=lambda x: x[0])  # remove possible duplicates and sort based on the address\n\n    cmd_args = {'output_file': args.output_file,\n                'files': files,\n                'pid': args.pid,\n                'part_size': args.part_size,\n                }\n\n    {'write': action_write\n     }[args.command](cmd_args)\n\n\nif __name__ == '__main__':\n    main()\n",
  "line_no": 174,
  "line_no_percent": "70%"
}