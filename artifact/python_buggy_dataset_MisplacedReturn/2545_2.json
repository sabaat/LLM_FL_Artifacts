{
  "instruction": "Create a Python script that extracts text from a webpage and stores it in a SQLite database. The script should import the following libraries: sqlite3, urllib, re, BeautifulSoup, NavigableString, and nltk. It should download the 'punkt' package from the nltk library. The script should define a function called 'parseRes2' that takes in a BeautifulSoup object, a title, a URL, a cursor object, an author, a date, and a collection title. The function should extract text from the webpage and store it in the SQLite database. The script should define a main function that connects to the database, creates a table called 'texts', and deletes any existing entries for the author 'Johannes de Plano Carpini'. The main function should then call the 'parseRes2' function to extract text from a specific webpage and store it in the database.",
  "buggy_code": "import sqlite3\nimport urllib\nimport re\nfrom urllib.request import urlopen\nfrom bs4 import BeautifulSoup, NavigableString\n\nimport nltk\n\nnltk.download('punkt')\n\nfrom nltk import sent_tokenize\n\ndef parseRes2(soup, title, url, cur, author, date, collectiontitle):\n    chapter = 0\n    sen = \"\"\n    num = 1\n    [e.extract() for e in soup.find_all('br')]\n    [e.extract() for e in soup.find_all('table')]\n    [e.extract() for e in soup.find_all('span')]\n    [e.extract() for e in soup.find_all('a')]\n    for x in soup.find_all():\n        if len(x.text) == 0:\n            x.extract()\n    getp = soup.find_all('p')\n    i = 0\n    for p in getp:\n        try:\n            if p['class'][0].lower() in ['border', 'pagehead', 'shortborder', 'smallboarder', 'margin',\n                                         'internal_navigation']:  # these are not part of the main t\n                continue\n        except:\n            pass\n        if p.b:\n            chapter = p.b.text\n            chapter = chapter.strip()\n        else:\n            sen = p.text\n            sen = sen.strip()\n            if sen != '':\n                num = 0\n                for s in sent_tokenize(sen):\n                    sentn = s.strip()\n                    num += 1\n                    cur.execute(\"INSERT INTO texts VALUES (?,?,?,?,?,?,?, ?, ?, ?, ?)\",\n                                (None, collectiontitle, title, 'Latin', author, date, chapter,\n                                 num, sentn, url, 'prose'))\n\n\ndef main():\n    return\n    siteURL = 'http://www.thelatinlibrary.com'\n    biggsURL = 'http://www.thelatinlibrary.com/johannes.html'\n    biggsOPEN = urllib.request.urlopen(biggsURL)\n    biggsSOUP = BeautifulSoup(biggsOPEN, 'html5lib')\n    textsURL = []\n\n    title = 'Johannes de Plano Carpini'\n\n    author = title\n    collectiontitle = 'JOHANNES DE PLANO CARPINI LIBELLUS HISTORICUS IOANNIS DE PLANO CARPINI'\n    date = '1246 A.D.'\n\n    with sqlite3.connect('texts.db') as db:\n        c = db.cursor()\n        c.execute(\n        'CREATE TABLE IF NOT EXISTS texts (id INTEGER PRIMARY KEY, title TEXT, book TEXT,'\n        ' language TEXT, author TEXT, date TEXT, chapter TEXT, verse TEXT, passage TEXT,'\n        ' link TEXT, documentType TEXT)')\n        c.execute(\"DELETE FROM texts WHERE author = 'Johannes de Plano Carpini'\")\n        parseRes2(biggsSOUP, title, biggsURL, c, author, date, collectiontitle)\n\n\nif __name__ == '__main__':\n    main()\n",
  "line_no": 50,
  "line_no_percent": "68%"
}