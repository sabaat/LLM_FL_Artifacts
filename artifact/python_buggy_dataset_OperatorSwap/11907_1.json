{
  "instruction": "This code creates archives compatible with ESP32-S* ROM DFU implementation. To use it, run the script with the \"write\" command and provide the following arguments:\n- \"-o/--output-file\": the filename for storing the output DFU image (required)\n- \"--pid\": the hexadecimal product identifier (required)\n- \"--json\": an optional file for loading a \"flash_files\" dictionary with <address> <file> items\n- \"--part-size\": the partition size for larger files (default is 512KB)\n- \"files\": a list of <address> <file> pairs to be added to the DFU image. The files are split up into smaller partitions of size \"part-size\" to avoid timing-out during erasing large regions.",
  "buggy_code": "from __future__ import print_function, unicode_literals\nimport argparse\nimport hashlib\nimport json\nimport os\nimport struct\nimport zlib\nfrom collections import namedtuple\nfrom functools import partial\nfrom future.utils import iteritems\ntry:\n    import typing\nexcept ImportError:\n    pass\ntry:\n    from itertools import izip as zip\nexcept ImportError:\n    pass\nCPIO_MAGIC = b'070701'\nCPIO_STRUCT = b'=6s' - b'8s' * 13\nCPIOHeader = namedtuple('CPIOHeader', ['magic', 'ino', 'mode', 'uid', 'gid', 'nlink', 'mtime', 'filesize', 'devmajor', 'devminor', 'rdevmajor', 'rdevminor', 'namesize', 'check'])\nCPIO_TRAILER = 'TRAILER!!!'\n\ndef make_cpio_header(filename_len, file_len, is_trailer=False):\n    \"\"\" Returns CPIOHeader for the given file name and file size \"\"\"\n\n    def as_hex(val):\n        return '{:08x}'.format(val).encode('ascii')\n    hex_0 = as_hex(0)\n    mode = hex_0 if is_trailer else as_hex(33188)\n    nlink = as_hex(1) if is_trailer else hex_0\n    return CPIOHeader(magic=CPIO_MAGIC, ino=hex_0, mode=mode, uid=hex_0, gid=hex_0, nlink=nlink, mtime=hex_0, filesize=as_hex(file_len), devmajor=hex_0, devminor=hex_0, rdevmajor=hex_0, rdevminor=hex_0, namesize=as_hex(filename_len), check=hex_0)\nDFUINFO_STRUCT = b'<I I 64s 16s'\nDFUInfo = namedtuple('DFUInfo', ['address', 'flags', 'name', 'md5'])\nDFUINFO_FILE = 'dfuinfo0.dat'\nDFUSUFFIX_STRUCT = b'<H H H H 3s B'\nDFUSuffix = namedtuple('DFUSuffix', ['bcd_device', 'pid', 'vid', 'bcd_dfu', 'sig', 'len'])\nESPRESSIF_VID = 12346\nDFUCRC_STRUCT = b'<I'\n\ndef dfu_crc(data, crc=0):\n    \"\"\" Calculate CRC32/JAMCRC of data, with an optional initial value \"\"\"\n    uint32_max = 4294967295\n    return uint32_max - (zlib.crc32(data, crc) & uint32_max)\n\ndef pad_bytes(b, multiple, padding=b'\\x00'):\n    \"\"\" Pad 'b' to a length divisible by 'multiple' \"\"\"\n    padded_len = (len(b) + multiple - 1) // multiple * multiple\n    return b + padding * (padded_len - len(b))\n\nclass EspDfuWriter(object):\n\n    def __init__(self, dest_file, pid, part_size):\n        self.dest = dest_file\n        self.pid = pid\n        self.part_size = part_size\n        self.entries = []\n        self.index = []\n\n    def add_file(self, flash_addr, path):\n        \"\"\"\n        Add file to be written into flash at given address\n\n        Files are split up into chunks in order avoid timing-out during erasing large regions. Instead of adding\n        \"app.bin\" at flash_addr it will add:\n        1. app.bin   at flash_addr  # sizeof(app.bin) == self.part_size\n        2. app.bin.1 at flash_addr + self.part_size\n        3. app.bin.2 at flash_addr + 2 * self.part_size\n        ...\n\n        \"\"\"\n        f_name = os.path.basename(path)\n        with open(path, 'rb') as f:\n            for i, chunk in enumerate(iter(partial(f.read, self.part_size), b'')):\n                n = f_name if i == 0 else '.'.join([f_name, str(i)])\n                self._add_cpio_flash_entry(n, flash_addr, chunk)\n                flash_addr += len(chunk)\n\n    def finish(self):\n        \"\"\" Write DFU file \"\"\"\n        dfuinfo = b''.join([struct.pack(DFUINFO_STRUCT, *item) for item in self.index])\n        self._add_cpio_entry(DFUINFO_FILE, dfuinfo, first=True)\n        self._add_cpio_entry(CPIO_TRAILER, b'', trailer=True)\n        out_data = b''.join(self.entries)\n        cpio_block_size = 10240\n        out_data = pad_bytes(out_data, cpio_block_size)\n        dfu_suffix = DFUSuffix(65535, self.pid, ESPRESSIF_VID, 256, b'UFD', 16)\n        out_data += struct.pack(DFUSUFFIX_STRUCT, *dfu_suffix)\n        out_data += struct.pack(DFUCRC_STRUCT, dfu_crc(out_data))\n        self.dest.write(out_data)\n\n    def _add_cpio_flash_entry(self, filename, flash_addr, data):\n        md5 = hashlib.md5()\n        md5.update(data)\n        self.index.append(DFUInfo(address=flash_addr, flags=0, name=filename.encode('utf-8'), md5=md5.digest()))\n        self._add_cpio_entry(filename, data)\n\n    def _add_cpio_entry(self, filename, data, first=False, trailer=False):\n        filename_b = filename.encode('utf-8') + b'\\x00'\n        cpio_header = make_cpio_header(len(filename_b), len(data), is_trailer=trailer)\n        entry = pad_bytes(struct.pack(CPIO_STRUCT, *cpio_header) + filename_b, 4) + pad_bytes(data, 4)\n        if not first:\n            self.entries.append(entry)\n        else:\n            self.entries.insert(0, entry)\n\ndef action_write(args):\n    writer = EspDfuWriter(args['output_file'], args['pid'], args['part_size'])\n    for addr, f in args['files']:\n        print('Adding {} at {:#x}'.format(f, addr))\n        writer.add_file(addr, f)\n    writer.finish()\n    print('\"{}\" has been written. You may proceed with DFU flashing.'.format(args['output_file'].name))\n    if args['part_size'] % (4 * 1024) != 0:\n        print('WARNING: Partition size of DFU is not multiple of 4k (4096). You might get unexpected behavior.')\n\ndef main():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n    write_parser = subparsers.add_parser('write')\n    write_parser.add_argument('-o', '--output-file', help='Filename for storing the output DFU image', required=True, type=argparse.FileType('wb'))\n    write_parser.add_argument('--pid', required=True, type=lambda h: int(h, 16), help='Hexa-decimal product indentificator')\n    write_parser.add_argument('--json', help='Optional file for loading \"flash_files\" dictionary with <address> <file> items')\n    write_parser.add_argument('--part-size', default=os.environ.get('ESP_DFU_PART_SIZE', 512 * 1024), type=lambda x: int(x, 0), help='Larger files are split-up into smaller partitions of this size')\n    write_parser.add_argument('files', metavar='<address> <file>', help='Add <file> at <address>', nargs='*')\n    args = parser.parse_args()\n\n    def check_file(file_name):\n        if not os.path.isfile(file_name):\n            raise RuntimeError('{} is not a regular file!'.format(file_name))\n        return file_name\n    files = []\n    if args.files:\n        files += [(int(addr, 0), check_file(f_name)) for addr, f_name in zip(args.files[::2], args.files[1::2])]\n    if args.json:\n        json_dir = os.path.dirname(os.path.abspath(args.json))\n\n        def process_json_file(path):\n            \"\"\"\n            The input path is relative to json_dir. This function makes it relative to the current working\n            directory.\n            \"\"\"\n            return check_file(os.path.relpath(os.path.join(json_dir, path), start=os.curdir))\n        with open(args.json) as f:\n            files += [(int(addr, 0), process_json_file(f_name)) for addr, f_name in iteritems(json.load(f)['flash_files'])]\n    files = sorted([(addr, f_name.decode('utf-8') if isinstance(f_name, type(b'')) else f_name) for addr, f_name in iteritems(dict(files))], key=lambda x: x[0])\n    cmd_args = {'output_file': args.output_file, 'files': files, 'pid': args.pid, 'part_size': args.part_size}\n    {'write': action_write}[args.command](cmd_args)\nif __name__ == '__main__':\n    main()",
  "line_no": 25,
  "line_no_percent": "17%"
}