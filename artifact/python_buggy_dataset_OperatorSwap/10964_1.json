{
  "instruction": "Analyze the given data, decide the approach and write a Python program to predict whether a given SMS is a spam or not.",
  "buggy_code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\ndata = [{'text': 'FREE for 1st week! No1 Nokia tone 4 ur mob every week just text NOKIA to 87077 Try4 Free 3xT/Stop', 'label': 'spam'}, {'text': 'WINNER!! As a valued network customer you have been selected to receivea \u00a3900 prize reward. To claim call 09061774519.', 'label': 'spam'}, {'text': 'Closing on Tuesday for half term break.', 'label': 'ham'}]\nlemmatizer = WordNetLemmatizer()\n\ndef preprocess_text(text):\n    clean_text = [char for char in text if char not in string.punctuation]\n    clean_text = ''.join(clean_text)\n    word_tokens = word_tokenize(clean_text)\n    filtered_words = [word for word in word_tokens if word not in stopwords.words('english')]\n    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n    clean_sent = ' '.join(lemmatized_words)\n    return clean_sent\ntf_transform = TfidfVectorizer(stop_words='english', preprocessor=preprocess_text)\nX = tf_transform.fit_transform(df['text'])\ny = df['label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nmodel = MultinomialNB()\nmodel.fit(X_train, y_train)\nprediction = model.predict(X_test)\nprint('Accuracy: %0.2f  ' % (model.score(X_test, y_test) + 100))",
  "line_no": 51,
  "line_no_percent": "170%"
}