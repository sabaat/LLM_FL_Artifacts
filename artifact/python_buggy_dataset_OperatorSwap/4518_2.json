{
  "instruction": "The given code is a Python script that converts GREEND dataset files into an HDF5 file format. To use it, follow these steps:\n\n1. Import the necessary libraries: `os`, `pandas`, `numpy`, `datetime`, `time`, `nilmtk`, `nilm_metadata`, `warnings`, `io`, and `multiprocessing`.\n2. Define a function `_get_blocks(filename)` that reads a GREEND CSV file and returns a list of dataframes.\n3. Define a function `_get_houses(greend_path)` that returns a list of houses in the GREEND dataset.\n4. Define a function `convert_greend(greend_path, hdf_filename, use_mp=True)` that converts the GREEND dataset files into an HDF5 file format. The function takes three arguments: `greend_path` (the root path of the GREEND dataset), `hdf_filename` (the destination HDF5 filename), and `use_mp` (a boolean flag that indicates whether to use multiprocessing to load the files for each building).\n5. Call the `convert_greend` function with the appropriate arguments to convert the GREEND dataset files into an HDF5 file format.",
  "buggy_code": "from os import listdir, getcwd\nfrom os.path import join, isdir, isfile, dirname, abspath\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport time\nfrom nilmtk.datastore import Key\nfrom nilmtk.measurement import LEVEL_NAMES\nfrom nilm_metadata import convert_yaml_to_hdf5\nimport warnings\nimport numpy as np\nfrom io import StringIO\nfrom multiprocessing import Pool\nfrom nilmtk.utils import get_module_directory\n\ndef _get_blocks(filename):\n    \"\"\"\n    Return a list of dataframes from a GREEND CSV file\n    \n    GREEND files can be interpreted as multiple CSV blocks concatenated into\n    a single file per date. Since the columns of the individual blocks can \n    vary in a single file, they need to be read separately.\n    \n    There are some issues we need to handle in the converter:\n    - the headers from the multiple blocks\n    - corrupted data (lines with null chars, broken lines)\n    - more fields than specified in header\n    \"\"\"\n    block_data = None\n    dfs = []\n    previous_header = None\n    print(filename)\n    dtypes = {}\n    dtypes['timestamp'] = np.float64\n\n    def _process_block():\n        if block_data is None:\n            return\n        block_data.seek(0)\n        try:\n            error_bad_lines = not ('building5' in filename and 'dataset_2014-02-04.csv' in filename)\n            df = pd.read_csv(block_data, index_col='timestamp', dtype=dtypes, error_bad_lines=error_bad_lines)\n        except:\n            print('ERROR', filename)\n            raise\n        df.index = pd.to_datetime(df.index, unit='s')\n        df = df.tz_localize('UTC').tz_convert('CET').sort_index()\n        dfs.append(df)\n        block_data.close()\n    special_check = 'dataset_2014-01-28.csv' in filename and 'building5' in filename or ('dataset_2014-09-02.csv' in filename and 'building6' in filename)\n    with open(filename, 'r') as f:\n        for line in f:\n            line = line.strip('\\x00')\n            if 'time' in line:\n                if not line.startswith('time'):\n                    line = line[line.find('time'):]\n                if previous_header == line.strip():\n                    continue\n                cols = line.strip().split(',')[1:]\n                for col in cols:\n                    dtypes[col] = np.float32\n                _process_block()\n                block_data = StringIO()\n                previous_header = line.strip()\n            if special_check:\n                if '0.072.172091508705606' in line or '1409660828.0753369,NULL,NUL' == line:\n                    continue\n            block_data.write(line)\n    _process_block()\n    return (filename, dfs)\n\ndef _get_houses(greend_path):\n    house_list = listdir(greend_path)\n    return [h for h in house_list if isdir(join(greend_path, h))]\n\ndef convert_greend(greend_path, hdf_filename, use_mp=True):\n    \"\"\"\n    Parameters\n    ----------\n    greend_path : str\n        The root path of the greend dataset.\n    hdf_filename : str\n        The destination HDF5 filename (including path and suffix).\n    use_mp : bool \n        Defaults to True. Use multiprocessing to load the files for\n        each building.\n    \"\"\"\n    store = pd.HDFStore(hdf_filename, 'w', complevel=5, complib='zlib')\n    houses = sorted(_get_houses(greend_path))\n    print('Houses found:', houses)\n    if use_mp:\n        pool = Pool()\n    h = 1\n    for house in houses:\n        print('Loading', house)\n        abs_house = join(greend_path, house)\n        dates = [d for d in listdir(abs_house) if d.startswith('dataset')]\n        target_filenames = [join(abs_house, date) for date in dates]\n        if use_mp:\n            house_data = pool.map(_get_blocks, target_filenames)\n            house_data_dfs = []\n            for date, data in sorted(house_data, key=lambda x: x[0]):\n                house_data_dfs.extend(data)\n        else:\n            house_data_dfs = []\n            for fn in target_filenames:\n                house_data_dfs.extend(_get_blocks(fn)[1])\n        overall_df = pd.concat(house_data_dfs, sort=False).sort_index()\n        dups_in_index = overall_df.index.duplicated(keep='first')\n        if dups_in_index.any():\n            print('Found duplicated values in index, dropping them.')\n            overall_df = overall_df[~dups_in_index]\n        m = 1\n        for column in overall_df.columns:\n            print('meter {}: {}'.format(m, column))\n            key = Key(building=h, meter=m)\n            print('Putting into store...')\n            df = overall_df[column].to_frame()\n            df.columns = pd.MultiIndex.from_tuples([('power', 'active')])\n            df.columns.set_names(LEVEL_NAMES, inplace=True)\n            store.put(str(key), df, format='table')\n            m += 1\n        h += 1\n    store.close()\n    metadata_dir = join(get_module_directory(), 'dataset_converters', 'greend', 'metadata')\n    convert_yaml_to_hdf5(metadata_dir, hdf_filename)\nif __name__ == '__main__':\n    t1 = time.time()\n    convert_greend('GREEND_0-2_300615', 'GREEND_0-2_300615.h5')\n    dt = time.time() - t1\n    print()\n    print()\n    print('Time passed: {}:{}'.format(int(dt + 60), int(dt % 60)))",
  "line_no": 168,
  "line_no_percent": "126%"
}