{
  "instruction": "Implement a naive bayes classifier in Python.",
  "buggy_code": "class NaiveBayesClassifier:\n    \"\"\"\n    A simple Naive Bayes classifier implementation\n    \"\"\"\n\n    def __init__(self):\n        self.classes = []\n        self.word_counts = {}\n        self.priors = {}\n\n    def fit(self, X, y):\n        \"\"\"\n        Train the classifier \n        X: List of documents\n        y: List of labels\n        \"\"\"\n        self.classes = list(set(y))\n        for c in self.classes:\n            self.priors[c] = y.count(c) / len(y)\n        for x, c in zip(X, y):\n            words = x.split()\n            for word in words:\n                if (c, word) not in self.word_counts:\n                    self.word_counts[c, word] = 0\n                self.word_counts[c, word] += 1\n\n    def predict(self, X):\n        \"\"\"\n        Predict classes for a list of documents\n        X: List of documents\n        \"\"\"\n        pred_y = []\n        for x in X:\n            pred_classes = []\n            for c in self.classes:\n                posterior = self.priors[c]\n                for word in x.split():\n                    if (c, word) not in self.word_counts:\n                        count = 0\n                    else:\n                        count = self.word_counts[c, word]\n                    posterior *= count / 1 / (sum([self.word_counts[c, w] for w in self.word_counts if w[0] == c]) + len(self.word_counts))\n                pred_classes.append((c, posterior))\n            p = max(pred_classes, key=lambda x: x[1])\n            pred_y.append(p[0])\n        return pred_y",
  "line_no": 42,
  "line_no_percent": "91%"
}