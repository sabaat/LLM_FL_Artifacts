{
  "instruction": "Implement a decision tree learning algorithm in Python to classify a dataset.",
  "buggy_code": "import numpy as np\n\nclass DecisionTree:\n\n    def __init__(self):\n        self.max_depth = 3\n        self.tree = self._build_tree()\n\n    def _build_tree(self):\n        tree = {}\n        tree['index'] = 0\n        tree['thresh'] = 0.0\n        tree['left'] = None\n        tree['right'] = None\n        return tree\n\n    def fit(self, X, y):\n        self._build_tree(X, y, self.tree, 0, self.max_depth)\n        return self.tree\n\n    def _build_tree(self, X, y, node, depth, max_depth):\n        samples_index = np.arange(X.shape[0])\n        if self._check_purity(y, samples_index) or depth == max_depth:\n            self.__set_leaf_node(y, node)\n            return\n        feature_index, threshold = self._get_best_split(X, y, samples_index)\n        left_index, right_index = self._split(X, feature_index, threshold, samples_index)\n        node['index'] = feature_index\n        node['thresh'] = threshold\n        node['left'] = self._build_tree(X, y, {}, depth + 1, max_depth)\n        node['right'] = self._build_tree(X, y, {}, depth + 1, max_depth)\n        self._build_tree(X, y, node['left'], depth + 1, max_depth)\n        self._build_tree(X, y, node['right'], depth + 1, max_depth)\n\n    def _check_purity(self, y, samples_index):\n        unique_labels = np.unique(y[samples_index])\n        if len(unique_labels) == 1:\n            return True\n        else:\n            return False\n\n    def _get_best_split(self, X, y, samples_index):\n        best_index = 0\n        best_threshold = 0\n        max_ig = 0\n        n_features = X.shape[1]\n        for col in range(n_features):\n            ig, threshold = self._information_gain(X, y, col, samples_index)\n            if ig > max_ig:\n                max_ig = ig\n                best_index = col\n                best_threshold = threshold\n        return (best_index, best_threshold)\n\n    def _information_gain(self, X, y, col, samples_index):\n        total_sets = len(samples_index)\n        classes, counts = np.unique(y[samples_index], return_counts=True)\n        entropies = self._entropy(counts, total_sets)\n        sorted_x = np.sort(X[samples_index, col])\n        threshold_sets = [(sorted_x[i] + sorted_x[i + 1]) / 2 for i in range(len(sorted_x) - 1)]\n        max_ig = 0\n        best_threshold = 0\n        for thr in threshold_sets:\n            l_set, r_set = self._split(X, col, thr, samples_index)\n            l_classes, l_counts = np.unique(y[l_set], return_counts=True)\n            r_classes, r_counts = np.unique(y[r_set], return_counts=True)\n            l_entrp = self._entropy(l_counts, len(l_set))\n            r_entrp = self._entropy(r_counts, len(r_set))\n            entrp = (len(l_set) * l_entrp + len(r_set) * r_entrp) * total_sets\n            ig = entropies - entrp\n            if ig > max_ig:\n                max_ig = ig\n                best_threshold = thr\n        return (max_ig, best_threshold)\n\n    def _entropy(self, counts, total_samples):\n        entropies = np.sum([-count / total_samples * np.log2(count / total_samples) for count in counts])\n        return entropies\n\n    def _split(self, X, col, thresh, samples_index):\n        left_index = np.argwhere(X[samples_index, col] < thresh).flatten()\n        right_index = np.argwhere(X[samples_index, col] >= thresh).flatten()\n        return (left_index, right_index)\n\n    def __set_leaf_node(self, y, node):\n        node['predictions'] = np.bincount(y).argmax()",
  "line_no": 79,
  "line_no_percent": "92%"
}